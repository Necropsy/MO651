{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalho 2 - Robótica Movel - MO651\n",
    "#### __Professor(a):__ _Esther Luna Columbini_ <br>\n",
    "__Alunos:__ <br>\n",
    "_Tito Barbosa Rezende_              __RA:__ 025327<br>\n",
    "_João Paulo Franco Assumpção_       __RA:__ 229322<br>\n",
    "_Elcio Pereira de Souza Junior_     __RA:__ 262952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisitos\n",
    "\n",
    "Instalação das bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install anglr\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.insert(0, '../src')\n",
    "from robot import Robot\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import vrep\n",
    "import math\n",
    "import multiprocessing\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Cinemático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      " Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      " Vision sensor connected.\n",
      " Laser connected.\n",
      " Left motor connected.\n",
      " Right motor connected.\n",
      " Robot connected.\n"
     ]
    }
   ],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Laser\n",
    "\n",
    "Nesta etapa definimos a classe para leitura dos dados que serão obtidos pelo sensor laser, e realizamos uma verificação sobre a obtenção destes dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser_sensor:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "\n",
    "    def update_robot_frame_reading(self):\n",
    "        laser_flatten_readings = np.array(self.robot.read_laser())\n",
    "        laser_readings = laser_flatten_readings.reshape((len(laser_flatten_readings)//3, 3))\n",
    "        self.laser_x = laser_readings[:,0]\n",
    "        self.laser_y = laser_readings[:,1]\n",
    "laser_sensor = Laser_sensor(robot)\n",
    "laser_sensor.update_robot_frame_reading()\n",
    "\n",
    "def plot_lase_robot_frame():\n",
    "    fig, ax = plt.subplots()\n",
    "    #posição dos feixes laser\n",
    "    ax.scatter(laser_sensor.laser_x, laser_sensor.laser_y, 3, c='g', marker='o')\n",
    "    #posição do centro do robo\n",
    "    ax.scatter(0, 0, 40, c='b', marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Ultrassônico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a leitura correta dos sensores de proximidade, precisamos transformar a leitura do sensor em um ponto _(x,y)_ em relação ao frame do robo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Us_sensor:\n",
    "    def __init__(self,robot):\n",
    "        orientation_angles = np.array([90,50,30,10,-10,-30,-50,-90,-90,-130,-150,-170,170,150,130,90])\n",
    "        orientation_rad = np.radians(orientation_angles)\n",
    "        self.data = {\n",
    "        \"prefix\" : \"Pioneer_p3dx_ultrasonicSensor\",\n",
    "        \"ids\" : np.arange(1,17,1), \"handles\" : np.zeros(16, dtype=int), \n",
    "        \"positions\" :  np.zeros((16,3),dtype=float),\n",
    "        \"angles_deg\": orientation_angles,\n",
    "        \"angles_rad\": orientation_rad,\n",
    "        \"raw_reading\": np.zeros(16),\n",
    "        \"robot_frame_reading\": np.zeros((16,2),dtype=float)\n",
    "        }\n",
    "        self.robot = robot\n",
    "        \n",
    "        for i,sensor_i in enumerate(self.data['ids']):\n",
    "            ret,handle = vrep.simxGetObjectHandle(self.robot.clientID, self.data['prefix'] + str(sensor_i), vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['handles'][i] = handle\n",
    "            ret, pos = vrep.simxGetObjectPosition(self.robot.clientID, handle, self.robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            #ret, ang = vrep.simxGetObjectOrientation(robot.clientID, handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['positions'][i,:] = pos\n",
    "            #ultrassonic_sensors[sensor_i,4:7] = ang\n",
    "            \n",
    "    def get_left_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        #return np.min(np.array([self.data[\"raw_reading\"][0],self.data[\"raw_reading\"][1],self.data[\"raw_reading\"][15],self.data[\"raw_reading\"][14]]))\n",
    "        return np.min(np.array(self.data[\"raw_reading\"][:3]))\n",
    "    \n",
    "    def get_front_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][2:6]]))\n",
    "        #return np.min(np.array([self.data[\"raw_reading\"][2:4]]))\n",
    "    \n",
    "    def get_right_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][6:10]]))\n",
    "    \n",
    "    def update_raw_reading(self):\n",
    "        self.data[\"raw_reading\"] = np.array(self.robot.read_ultrassonic_sensors())\n",
    "    \n",
    "    def update_robot_frame_reading(self):\n",
    "        self.update_raw_reading()\n",
    "        for i, proximity in enumerate(us_sensors.data[\"raw_reading\"]):\n",
    "            if proximity == 5 or proximity < 0.1:\n",
    "                self.data[\"robot_frame_reading\"][i] = np.zeros(2)\n",
    "            else:\n",
    "                self.data[\"robot_frame_reading\"][i] = self.proximity_robot_frame(i+1,proximity).flatten()\n",
    "                \n",
    "        #toRobotFrame = lambda sensorId,proximity: self.proximity_robot_frame(sensorId,proximity)\n",
    "        #self.data[\"robot_frame_reading\"] = toRobotFrame(range(1,17,1),us_sensors.data[\"raw_reading\"])\n",
    "    \n",
    "    #Calcula o ponto no frame do robo, referente a leitura de cada sensor de proximidade\n",
    "    def proximity_robot_frame(self,sensorId, proximity):\n",
    "        index = sensorId -1\n",
    "        angulars = self.data[\"angles_rad\"][index]\n",
    "        #Matriz de rotação\n",
    "        rot_matrix = np.array([[math.cos(angulars),-math.sin(angulars)],[math.sin(angulars),math.cos(angulars)]])\n",
    "        #Rotacionando a leitura\n",
    "        distXY = np.dot(rot_matrix , np.array([[proximity],[0]]))\n",
    "        #Matriz de translação\n",
    "        posicao_sensor_x = self.data[\"positions\"][index][0]\n",
    "        posicao_sensor_y = self.data[\"positions\"][index][1]\n",
    "        transXY=np.array([[distXY[0][0]+posicao_sensor_x],[distXY[1][0]+posicao_sensor_y]])\n",
    "        return transXY\n",
    "\n",
    "us_sensors = Us_sensor(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos uma função _toGlobal_ (para termos um melhor reuso de código), basicamente a função transforma um ponto qualquer _(x,y)_ que esteja na referência do robô e o leva para a referência global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,robot_x],[0,1,robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),-math.sin(robot_ang),0],[math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_trans,T_rot)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    return res[0],res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9330127018922194, 4.116025403784438)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_to_global = toGlobal(2,3,np.radians(30),0.5,1)\n",
    "robot_to_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,-robot_x],[0,1,-robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),math.sin(robot_ang),0],[-math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_rot,T_trans)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    ang = np.arctan2(res[1],res[0])\n",
    "    return res[0],res[1], ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6339745962155616, 3.098076211353316, 1.3689481055932398)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_to_robot = fromGlobal(4,2,np.radians(30),3,5)\n",
    "global_to_robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.43494882292201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.degrees(global_to_robot[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Cinemático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado o movimento do robo, como determinar sua posição e orientação no frame global?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinematic_model:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "        \n",
    "        #Handles dos motores\n",
    "        ret1, self.motorLeft = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret2, self.motorRight = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        #Calcula distancia de eixo\n",
    "        res, left_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, lpos = vrep.simxGetObjectPosition(robot.clientID, left_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        res, right_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, rpos = vrep.simxGetObjectPosition(robot.clientID, right_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        # eixo\n",
    "        self.l = (abs(lpos[1]) + abs(rpos[1]))/2\n",
    "        \n",
    "        #Ao ser criado, coleta a referencia de zero do robo\n",
    "        pos = self.robot.get_current_position()\n",
    "        self.initial_pos_x = pos[0]\n",
    "        self.initial_pos_y = pos[1]\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        self.initial_orientation = orientation[2]\n",
    "\n",
    "        #Alem de mantermos a pose inicial, manteremos a pose atualizada do robo\n",
    "        self.enc_global_x = self.initial_pos_x\n",
    "        self.enc_global_y = self.initial_pos_y\n",
    "        self.enc_Theta = self.initial_orientation\n",
    "        \n",
    "        self.time_global_x = self.initial_pos_x\n",
    "        self.time_global_y = self.initial_pos_y\n",
    "        self.time_Theta = self.initial_orientation\n",
    "        \n",
    "        #Lista de pontos para o caminho do robo\n",
    "        self.enc_path = []\n",
    "        self.time_path = []\n",
    "        self.true_path = []\n",
    "        self.update_paths()\n",
    "        \n",
    "        #inicializando a posição dos encoders\n",
    "        self.jL = self.current_encoder_left()\n",
    "        self.jR = self.current_encoder_right()\n",
    "        \n",
    "        #intervalo entre cada calculo\n",
    "        self.compute_interval = 0.1\n",
    "        self.previous_timestamp = 0\n",
    "        \n",
    "    def update_paths(self):\n",
    "        self.enc_path.append([self.enc_global_x, self.enc_global_y, self.enc_Theta])\n",
    "        self.time_path.append([self.time_global_x, self.time_global_y, self.time_Theta])\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        true_theta = orientation[2]\n",
    "        current_position = self.true_global_position()\n",
    "        self.true_path.append([current_position[0], current_position[1], true_theta])\n",
    "    \n",
    "    def true_global_position(self):\n",
    "        pos = self.robot.get_current_position()\n",
    "        return pos[0],pos[1]\n",
    "    \n",
    "    def enc_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.enc_Theta\n",
    "    \n",
    "    def time_global_position(self):\n",
    "        return self.time_global_x, self.time_global_y, self.time_Theta\n",
    "    \n",
    "    \n",
    "    ##Esta seção esta relacionada ao calculo da posição levando em consideração os encoders\n",
    "    def current_encoder_left(self):\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_oneshot_wait)\n",
    "        return jL\n",
    "    def current_encoder_right(self):\n",
    "        ret, jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_oneshot_wait)\n",
    "        return jR\n",
    "        \n",
    "    #Phi speed of rotation of wheels\n",
    "    def Xr(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Xr = (r*Phi_left/2) + (r*Phi_right/2)\n",
    "        return Xr\n",
    "    \n",
    "    def Theta_r(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Tr = r*Phi_right/(2*self.l) - r*Phi_left/(2*self.l) \n",
    "        return Tr\n",
    "        \n",
    "    def speed_model(self,Phi_right,Phi_left):\n",
    "        #Se formos considerar que o eixo das rodas do robo está deslocado do eixo x\n",
    "        #return np.array([self.Xr(Phi_right,Phi_left),self.Theta_r(Phi_right,Phi_left)*self.l2,self.Theta_r(Phi_right,Phi_left)])\n",
    "        return np.array([self.Xr(Phi_right,Phi_left),0,self.Theta_r(Phi_right,Phi_left)])\n",
    "        \n",
    "    def inverse_rotation_matrix(self, ang):\n",
    "        Trot = np.array([[math.cos(ang), -math.sin(ang), 0], [math.sin(ang), math.cos(ang), 0], [0,0,1]])\n",
    "        return Trot\n",
    "    \n",
    "    def locomotion_global(self, ang, Phi_right, Phi_left):\n",
    "        return np.dot(self.inverse_rotation_matrix(ang),self.speed_model(Phi_right,Phi_left))\n",
    "    \n",
    "    def compute_with_encoder(self):\n",
    "        dxR = self.current_encoder_right() - self.jR\n",
    "        dxL = self.current_encoder_left() - self.jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.enc_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.enc_global_x = self.enc_global_x + qsi[0]\n",
    "        self.enc_global_y = self.enc_global_y + qsi[1]\n",
    "        self.enc_Theta = self.enc_Theta + qsi[2]\n",
    "        #Atualiza a posição dos encoders\n",
    "        self.jR = self.current_encoder_right()\n",
    "        self.jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "    \n",
    "    def compute_with_time(self, Phi_right, Phi_left):\n",
    "        #Calculo do delta S\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Vr = r*Phi_right\n",
    "        Vl = r*Phi_left\n",
    "        current_timestamp = datetime.timestamp(datetime.now())\n",
    "        Delta_t = current_timestamp - self.previous_timestamp\n",
    "        #atualiza timestamp imediatamente\n",
    "\n",
    "        self.previous_timestamp = current_timestamp\n",
    "        \n",
    "        Delta_s = (Vr + Vl)*Delta_t/2  \n",
    "        Delta_Theta = (Vr - Vl)*Delta_t/(2*self.l)\n",
    "    \n",
    "        self.time_global_x = self.time_global_x + Delta_s*math.cos(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_global_y = self.time_global_y + Delta_s*math.sin(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_Theta = self.time_Theta + Delta_Theta\n",
    "    \n",
    "    def move(self,Phi_right, Phi_left,seconds): #velocidade em rad/s\n",
    "        #Vamos fixar um tempo de 500ms para computar as distâncias\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #self.compute()\n",
    "            self.robot.set_right_velocity(Phi_right)\n",
    "            self.robot.set_left_velocity(Phi_left)\n",
    "            time.sleep(self.compute_interval)\n",
    "            self.compute_with_encoder()\n",
    "            self.compute_with_time(Phi_right, Phi_left)\n",
    "            self.update_paths()\n",
    "        self.robot.stop()\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def turn(self, input_ang, origin=\"Local\"):\n",
    "        orientation = math.degrees(self.robot.get_current_orientation()[2])\n",
    "        ang = math.degrees(input_ang)\n",
    "        print(\"Initial orientation \", orientation)\n",
    "        print(\"Ang \", ang)\n",
    "        vel = 0.2\n",
    "        ori = origin\n",
    "        if (ori == \"Local\") :\n",
    "            new_orientation = orientation + ang\n",
    "            print(\"Ref. Local\")\n",
    "        else :\n",
    "            if (ori == \"Global\") :\n",
    "                new_orientation = ang\n",
    "                print(\"Ref. Global\")\n",
    "            else :\n",
    "                return 'Erro: origem deve ser \"Local\" ou \"Global\". Caso são seja mencionado, a função adotará \"Local\" como valor escolhido.'\n",
    "        print(\"new orientation \", new_orientation)\n",
    "        if (new_orientation > math.degrees(math.pi)):\n",
    "            new_orientation = new_orientation - 2*math.degrees(math.pi)\n",
    "            print(\"corrected new orientation \", new_orientation)\n",
    "            vel = -vel\n",
    "        if (new_orientation < -math.degrees(math.pi)):\n",
    "            new_orientation = new_orientation + 2*math.degrees(math.pi)\n",
    "            print(\"corrected new orientation \", new_orientation)\n",
    "            #vel = -vel\n",
    "        \n",
    "        self.robot.set_right_velocity(vel)\n",
    "        self.robot.set_left_velocity(-vel)\n",
    "        while (math.fabs(new_orientation - orientation) > math.degrees(math.pi/180)):\n",
    "            #print(\"difference \", (new_orientation - orientation))\n",
    "            #tqdm.write(f\"difference  {(new_orientation - orientation)}\")\n",
    "            time.sleep(0.05)\n",
    "            orientation = math.degrees(self.robot.get_current_orientation()[2])\n",
    "            #print(\"curr orientation \", orientation)\n",
    "            #tqdm.write(f\"curr orientation {(orientation)}\")\n",
    "            sys.stdout.write(\"\\r\" + \"Diff \" + str((new_orientation - orientation)) + \" orientation \" + str(orientation))\n",
    "            sys.stdout.flush()\n",
    "        self.robot.stop()\n",
    "        print(\"curr orientation \", orientation)\n",
    "\n",
    "#         #DeltaS ARC =>  2*Pi*r /diff\n",
    "#         #Robot radius\n",
    "#         R = self.l/2\n",
    "#         print(\"R \", R)\n",
    "#         #wheel radius\n",
    "#         r = self.robot.WHEEL_RADIUS\n",
    "#         print(\"r \", r)\n",
    "#         #relation\n",
    "#         # whellAng = RobotAng * r/R\n",
    "#         #phi is radians/sec\n",
    "#         phi = ang*R/r\n",
    "#         print(\"phi \", phi)\n",
    "#         if ang>0:\n",
    "#             vel = 2*phi\n",
    "#         else:\n",
    "#             vel = -2*phi\n",
    "#         self.robot.set_right_velocity(vel)\n",
    "#         self.robot.set_left_velocity(-vel)\n",
    "#         time.sleep(1)\n",
    "#         self.compute_with_encoder()\n",
    "#         self.compute_with_time(vel, -vel)\n",
    "#         self.update_paths()\n",
    "#         self.robot.stop()\n",
    "#         self.timestamp = 0\n",
    "#         print(\"Final orientation \", self.robot.get_current_orientation()[2])\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def ICR_left(self, Phi_left, R, seconds):\n",
    "        Phi_right = Phi_left*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_left Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "    \n",
    "    def ICR_right(self, Phi_right, R, seconds):\n",
    "        Phi_left = Phi_right*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_right Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "  \n",
    "    def plot_paths(self):\n",
    "        enc_path = np.array(self.enc_path)\n",
    "        time_path = np.array(self.time_path)\n",
    "        true_path = np.array(self.true_path)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "        ax[0].scatter(enc_path[:,0], enc_path[:,1], 5, c='b', marker='o')\n",
    "        #ax[1].scatter(time_path[:,0], time_path[:,1], 5, c='g', marker='o')\n",
    "        ax[1].scatter(true_path[:,0], true_path[:,1], 5, c='r', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuvem de pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a nuvem de pontos, nós coletamos os dados fornecidos pelo laser (conjunto de pontos) que estão baseados no sistema de referência do robô, após aplicamos a transformação destes pontos para o sistema de referência global. Dados os pontos no sistema global nós realizamos a plotagem dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud():\n",
    "    def __init__(self, robot, us_sensors, laser_sensor):\n",
    "        self.robot = robot\n",
    "        self.us_sensors = us_sensors\n",
    "        self.laser_sensor = laser_sensor\n",
    "        \n",
    "        self.ultrassonic_points = []\n",
    "        self.laser_points = []\n",
    "        self.robot_points = []\n",
    "    \n",
    "    def update(self):\n",
    "        #Insere posição atual do robo\n",
    "        robot_x = self.robot.get_current_position()[0]\n",
    "        robot_y = self.robot.get_current_position()[1]\n",
    "        robot_ang = self.robot.get_current_orientation()[2]\n",
    "        \n",
    "        self.robot_points.append([robot_x,robot_y])\n",
    "\n",
    "        #Atualiza a leitura do laser e insere na nuvem de pontos\n",
    "        self.laser_sensor.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.laser_sensor.laser_x, self.laser_sensor.laser_y):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.laser_points.append([x,y])\n",
    "\n",
    "        #Atualiza a leitura do ultrassonico e insere na nuvem de pontos\n",
    "        self.us_sensors.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.us_sensors.data['robot_frame_reading'][:,0], self.us_sensors.data['robot_frame_reading'][:,1]):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.ultrassonic_points.append([x,y])\n",
    "    \n",
    "    def plot_point_cloud(self):\n",
    "        #Convertendo a nuvem de pontos em um array\n",
    "        ultrassonic_point_array = np.array(self.ultrassonic_points)\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        robot_path = np.array(self.robot_points)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        #posição do centro do robo\n",
    "        ax[0].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[0].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[0].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax[0].scatter(ultrassonic_point_array[:,0],ultrassonic_point_array[:,1], 10, c='magenta', marker='.')\n",
    "\n",
    "        #posição do centro do robo\n",
    "        ax[1].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[1].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[1].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor laser\n",
    "        ax[1].scatter(laser_point_array[:,0],laser_point_array[:,1], 10, c='r', marker='.')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "\n",
    "point_cloud = PointCloud(robot, us_sensors, laser_sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulamento\n",
    "A classe a seguir encapsula todos os modelos criados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PID():\n",
    "    def __init__(self, P=1, I=0.0, D=0.0, Derivator=0, Integrator=0, Integrator_max=500, Integrator_min=-500):\n",
    "        self.Kp=P\n",
    "        self.Ki=I\n",
    "        self.Kd=D\n",
    "        self.Derivator=Derivator\n",
    "        self.Integrator=Integrator\n",
    "        self.Integrator_max=Integrator_max\n",
    "        self.Integrator_min=Integrator_min\n",
    "        self.set_point=0.0\n",
    "        self.error=0.0\n",
    "\n",
    "    def update(self,current_value):\n",
    "        self.error = self.set_point - current_value\n",
    "        self.P_value = self.Kp * self.error\n",
    "        self.D_value = self.Kd * ( self.error - self.Derivator)\n",
    "        self.Derivator = self.error\n",
    "        self.Integrator = self.Integrator + self.error\n",
    "\n",
    "        if self.Integrator > self.Integrator_max:\n",
    "            self.Integrator = self.Integrator_max\n",
    "        elif self.Integrator < self.Integrator_min:\n",
    "            self.Integrator = self.Integrator_min\n",
    "\n",
    "        self.I_value = self.Integrator * self.Ki\n",
    "\n",
    "        PID = self.P_value + self.I_value + self.D_value\n",
    "        print(\"PID cv \",current_value ,\" sp \", self.set_point ,\" error \", self.error ,\" pid \", PID)\n",
    "        return PID\n",
    "\n",
    "    def setPoint(self,set_point):\n",
    "        self.set_point = set_point\n",
    "        self.Integrator=0\n",
    "        self.Derivator=0\n",
    "\n",
    "# \tdef setIntegrator(self, Integrator):\n",
    "# \t\tself.Integrator = Integrator\n",
    "\n",
    "# \tdef setDerivator(self, Derivator):\n",
    "# \t\tself.Derivator = Derivator\n",
    "\n",
    "# \tdef setKp(self,P):\n",
    "# \t\tself.Kp=P\n",
    "\n",
    "# \tdef setKi(self,I):\n",
    "# \t\tself.Ki=I\n",
    "\n",
    "# \tdef setKd(self,D):\n",
    "# \t\tself.Kd=D\n",
    "\n",
    "# \tdef getPoint(self):\n",
    "# \t\treturn self.set_point\n",
    "\n",
    "# \tdef getError(self):\n",
    "# \t\treturn self.error\n",
    "\n",
    "# \tdef getIntegrator(self):\n",
    "# \t\treturn self.Integrator\n",
    "\n",
    "# \tdef getDerivator(self):\n",
    "# \t\treturn self.Derivator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      " Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      " Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      " Vision sensor connected.\n",
      " Laser connected.\n",
      " Left motor connected.\n",
      " Right motor connected.\n",
      " Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.pidL = PID()\n",
    "        self.pidL.setPoint(0.5)\n",
    "#         self.pidF = PID()\n",
    "#         self.pidF.setPoint(1)\n",
    "        self.compute_interval = 0.5\n",
    "        self.follow_wall_side = \"LEFT\"\n",
    "        \n",
    "        self.curr_state = None\n",
    "        self.prev_state = None\n",
    "        \n",
    "        #self.fsm_states = ['MoveFoward','WallFollow','TurnRight','TurnBack']\n",
    "        \n",
    "    def checkCurrentState(self):\n",
    "        previous_state = self.curr_state\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        #Initial state: Move Foward\n",
    "        if (previous_state == None and self.prev_state == None):\n",
    "            self.curr_state = 'MoveFoward'\n",
    "    \n",
    "        #MF->TR\n",
    "        if (previous_state == 'MoveFoward' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #TR->WF\n",
    "        if (previous_state == 'TurnRight' and left <= 0.8):\n",
    "            self.curr_state = 'WallFollow'\n",
    "            \n",
    "        #WF->TR\n",
    "        if (previous_state == 'WallFollow' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #WF->MoveFoward\n",
    "        if (previous_state == 'WallFollow' and front == 5 and left > 0.7):\n",
    "            self.curr_state = 'MoveFoward'\n",
    "          \n",
    "        #update prev\n",
    "        self.prev_state = previous_state\n",
    "    \n",
    "    def control(self, left_distance, right_distance, front_distance ):\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        vel = 0\n",
    "        turn = 0\n",
    "        self.checkCurrentState()\n",
    "        \n",
    "        print(\"left \", left, \"right \", right, \"front \", front)\n",
    "        \n",
    "        #State Machine\n",
    "        ##Move foward\n",
    "        if (self.curr_state == 'MoveFoward'):\n",
    "            turn = 0\n",
    "            vel = 1\n",
    "        ##Turn Right\n",
    "        elif (self.curr_state == 'TurnRight'):\n",
    "            turn = 1\n",
    "            vel = 0\n",
    "        #Wall Follow\n",
    "        elif (self.curr_state == 'WallFollow'):\n",
    "            turn = self.pidL.update(left_distance)\n",
    "            vel = 1\n",
    "        #Turn Back\n",
    "#         elif (self.curr_state == 'TurnBack'):\n",
    "#             turn = -1\n",
    "#             vel = 0\n",
    "        \n",
    "        \n",
    "        print(\"State: \", self.curr_state)\n",
    "        self.prev_state = self.curr_state\n",
    "        return vel + turn, vel - turn\n",
    "\n",
    "    def start(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            Phi_l, Phi_r = self.control(self.us_sensors.get_left_distance(),self.us_sensors.get_right_distance(), self.us_sensors.get_front_distance())\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            #self.point_cloud.update()\n",
    "            #self.point_cloud.plot_point_cloud()\n",
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial orientation  -59.979470121007054\n",
      "Ang  0.0\n",
      "Ref. Global\n",
      "new orientation  0.0\n",
      "Diff 0.6958956378557474 orientation -0.6958956378557474curr orientation  -0.6958956378557474\n"
     ]
    }
   ],
   "source": [
    "mr.kinematicModel.turn(math.radians(90)) #turn(math.radians(90), \"Global\") para girar em relação ao ângulo global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ori  3.3161255787892263\n",
      "Ang  3.141592653589793\n",
      "Soma  6.457718232379019\n",
      "corrige  0.17453292519943275\n",
      "Diff  0.1745329251994332\n"
     ]
    }
   ],
   "source": [
    "ori = math.radians(190)\n",
    "print(\"Ori \", ori)\n",
    "ang = math.radians(180)\n",
    "print(\"Ang \", ang)\n",
    "soma = ori + ang\n",
    "print(\"Soma \", soma)\n",
    "if (soma > (2*math.pi)):\n",
    "    print(\"corrige \", soma - (2*math.pi))\n",
    "diff = ori - ang\n",
    "print(\"Diff \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d95a06d5c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mus_sensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_left_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mr' is not defined"
     ]
    }
   ],
   "source": [
    "mr.us_sensors.get_left_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.us_sensors.get_front_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left  0.08469276130199432 right  0.8774257898330688 front  0.0638599842786789\n",
      "State:  MoveFoward\n",
      "left  0.08469278365373611 right  0.8773500323295593 front  0.06386074423789978\n",
      "State:  TurnRight\n",
      "left  0.08303500711917877 right  5.0 front  0.16826145350933075\n",
      "PID cv  0.08303500711917877  sp  0.5  error  0.41696499288082123  pid  0.41696499288082123\n",
      "State:  WallFollow\n",
      "left  0.12364697456359863 right  5.0 front  0.7263195514678955\n",
      "PID cv  0.12364697456359863  sp  0.5  error  0.37635302543640137  pid  0.37635302543640137\n",
      "State:  WallFollow\n",
      "left  0.2360750436782837 right  5.0 front  0.6218048930168152\n",
      "PID cv  0.2360750436782837  sp  0.5  error  0.2639249563217163  pid  0.2639249563217163\n",
      "State:  WallFollow\n",
      "left  0.4129619598388672 right  5.0 front  0.5152004957199097\n",
      "PID cv  0.4129619598388672  sp  0.5  error  0.08703804016113281  pid  0.08703804016113281\n",
      "State:  WallFollow\n",
      "left  0.47235774993896484 right  5.0 front  0.43444210290908813\n",
      "State:  TurnRight\n",
      "left  0.4583037197589874 right  0.33112895488739014 front  5.0\n",
      "PID cv  0.4583037197589874  sp  0.5  error  0.04169628024101257  pid  0.04169628024101257\n",
      "State:  WallFollow\n",
      "left  0.4880107343196869 right  0.4427061975002289 front  5.0\n",
      "PID cv  0.4880107343196869  sp  0.5  error  0.01198926568031311  pid  0.01198926568031311\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.586754322052002 front  5.0\n",
      "State:  TurnBack\n",
      "left  0.5071079730987549 right  5.0 front  5.0\n",
      "PID cv  0.5071079730987549  sp  0.5  error  -0.007107973098754883  pid  -0.007107973098754883\n",
      "State:  WallFollow\n",
      "left  0.4460025429725647 right  5.0 front  5.0\n",
      "PID cv  0.4460025429725647  sp  0.5  error  0.0539974570274353  pid  0.0539974570274353\n",
      "State:  WallFollow\n",
      "left  0.43556666374206543 right  5.0 front  5.0\n",
      "PID cv  0.43556666374206543  sp  0.5  error  0.06443333625793457  pid  0.06443333625793457\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  5.0\n",
      "State:  TurnBack\n",
      "left  5.0 right  5.0 front  5.0\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.4181891679763794 front  0.9192612171173096\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  0.5106971859931946\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.8605345487594604 front  5.0\n",
      "State:  TurnBack\n",
      "left  0.5366254448890686 right  5.0 front  5.0\n",
      "PID cv  0.5366254448890686  sp  0.5  error  -0.036625444889068604  pid  -0.036625444889068604\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  5.0\n",
      "State:  TurnBack\n",
      "left  5.0 right  5.0 front  5.0\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.9883793592453003 front  5.0\n",
      "State:  TurnBack\n",
      "left  5.0 right  0.9075541496276855 front  5.0\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  0.5034481287002563\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  5.0\n",
      "State:  TurnBack\n",
      "left  5.0 right  5.0 front  5.0\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.4972269833087921 front  0.9291285872459412\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  0.949724555015564 right  5.0 front  0.6091654300689697\n",
      "PID cv  0.949724555015564  sp  0.5  error  -0.44972455501556396  pid  -0.44972455501556396\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.5100067853927612 front  0.6371926665306091\n",
      "PID cv  5.0  sp  0.5  error  -4.5  pid  -4.5\n",
      "State:  WallFollow\n",
      "left  5.0 right  0.7462857961654663 front  5.0\n",
      "State:  TurnBack\n",
      "left  0.6591849327087402 right  5.0 front  5.0\n",
      "PID cv  0.6591849327087402  sp  0.5  error  -0.15918493270874023  pid  -0.15918493270874023\n",
      "State:  WallFollow\n",
      "left  0.625652551651001 right  5.0 front  5.0\n",
      "PID cv  0.625652551651001  sp  0.5  error  -0.12565255165100098  pid  -0.12565255165100098\n",
      "State:  WallFollow\n",
      "left  5.0 right  5.0 front  5.0\n",
      "State:  TurnBack\n"
     ]
    }
   ],
   "source": [
    "mr.start(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.kinematicModel.move(-1, -1, 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "<br>\n",
    "Para o projeto ultilizamos os seguintes sensores:\n",
    "\n",
    "* Encoders\n",
    "* Sensores Ultrassônicos\n",
    "* Laser Hokuyo\n",
    "* Câmera\n",
    "<br><br>\n",
    "<div style=\"text-align: justify\">\n",
    "Os encoders foram utilizados para o processo de odometria, com os dados fornecidos por eles nós estimamos o deslocamento realizado pelo robô no ambiente. Já os sensores ultrassônicos utilizamos para detectar objetos que estivessem mais próximos do robô devido seu curto alcance, porém focamos na utilização do laser para criação da nuvem de pontos por apresentar uma maior precisão e alcance. A utilização da câmera durante o processo foi especificamente para depuração do código, durante a construção do mesmo utilizamos ela para ter uma melhor visão do que estava sendo observado pelo robô.\n",
    "Como mencionado anteriormente os dados obtidos durante a coleta apresentam algumas variações em relação aos dados reais fornecidos pelo simulador V-REP (variações visíveis na odometria), estas variações são mais perceptíveis quando principalmente o robô realiza mudanças de direção, acreditamos que isto deve ocorrer pelo fato da imprecisão dos sensores (neste caso o encoder), o que gera um erro durante os cálculos de estimação de posição, tendo assim um acúmulo de erros durante todo o processo. Uma alternativa para a correção deste erro é a de utilização dos dados do laser como alternativa para minimização destes erros, onde poderíamos pegar pontos de referência na nuvem de pontos para calcularmos os ângulos de rotação e o deslocamento, porém o aperfeiçoamento deste modelo deve ser realizado somente na próxima etapa do trabalho.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
