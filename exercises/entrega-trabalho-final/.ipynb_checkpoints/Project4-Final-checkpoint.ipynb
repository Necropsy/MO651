{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 4 - Mobile Robotics - MO651\n",
    "#### __Professor:__ _Esther Luna Columbini_ <br>\n",
    "__Students:__ <br>\n",
    "<table style=\"margin:0; padding:3px;\">\n",
    "<tr><td><em>Tito Barbosa Rezende </td><td><strong>RA:</strong> 025327</td></tr>\n",
    "<tr><td><em>João Paulo Franco Assumpção </td><td><strong>RA:</strong> 229322</td></tr>\n",
    "<tr><td><em>Elcio Pereira de Souza Junior </td><td><strong>RA:</strong> 262952</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib) (1.17.2)\n",
      "Requirement already satisfied: six in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (1.17.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from opencv-python) (1.17.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-fuzzy in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.6.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-fuzzy) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.9.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-fuzzy) (1.3.1)\n",
      "Requirement already satisfied: networkx>=1.9.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-fuzzy) (2.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from networkx>=1.9.0->scikit-fuzzy) (4.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-image in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (0.16.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (1.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (3.1.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (2.3)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-image) (6.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scipy>=0.19.0->scikit-image) (1.17.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (41.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/titobr/mestrado/robotics/notebooks/jupyter_vrep/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install scikit-fuzzy\n",
    "%pip install scikit-image\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.insert(0, '../src')\n",
    "from IPython.display import clear_output\n",
    "from robot import Robot\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import vrep\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import lidar_to_grid_map as lg\n",
    "import grid_map_lib as gm\n",
    "import operator\n",
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Laser Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser_sensor:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "\n",
    "    def update_robot_frame_reading(self):\n",
    "        laser_flatten_readings = np.array(self.robot.read_laser())\n",
    "        laser_readings = laser_flatten_readings.reshape((len(laser_flatten_readings)//3, 3))\n",
    "        self.laser_x = laser_readings[:,0]\n",
    "        self.laser_y = laser_readings[:,1]\n",
    "\n",
    "    def plot_laser_robot_frame(self):\n",
    "        ox = self.laser_x\n",
    "        oy = self.laser_y\n",
    "        plt.figure(figsize=(6,10))\n",
    "        plt.plot([oy, np.zeros(np.size(oy))], [ox, np.zeros(np.size(oy))], \"ro-\") # lines from 0,0 to the \n",
    "        plt.axis(\"equal\")\n",
    "        bottom, top = plt.ylim()  # return the current ylim\n",
    "        plt.ylim((top, bottom)) # rescale y axis, to match the grid orientation\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sonar Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Us_sensor:\n",
    "    def __init__(self,robot):\n",
    "        orientation_angles = np.array([90,50,30,10,-10,-30,-50,-90,-90,-130,-150,-170,170,150,130,90])\n",
    "        orientation_rad = np.radians(orientation_angles)\n",
    "        self.data = {\n",
    "        \"prefix\" : \"Pioneer_p3dx_ultrasonicSensor\",\n",
    "        \"ids\" : np.arange(1,17,1), \"handles\" : np.zeros(16, dtype=int), \n",
    "        \"positions\" :  np.zeros((16,3),dtype=float),\n",
    "        \"angles_deg\": orientation_angles,\n",
    "        \"angles_rad\": orientation_rad,\n",
    "        \"raw_reading\": np.zeros(16),\n",
    "        \"robot_frame_reading\": np.zeros((16,2),dtype=float)\n",
    "        }\n",
    "        self.robot = robot\n",
    "        \n",
    "        for i,sensor_i in enumerate(self.data['ids']):\n",
    "            ret,handle = vrep.simxGetObjectHandle(self.robot.clientID, self.data['prefix'] + str(sensor_i), vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['handles'][i] = handle\n",
    "            ret, pos = vrep.simxGetObjectPosition(self.robot.clientID, handle, self.robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['positions'][i,:] = pos\n",
    "        \n",
    "    def get_left_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array(self.data[\"raw_reading\"][0]))\n",
    "    \n",
    "    def get_front_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][3:5]]))        \n",
    "    \n",
    "    def get_right_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][7:9]]))\n",
    "    \n",
    "    def update_raw_reading(self):\n",
    "        self.data[\"raw_reading\"] = np.array(self.robot.read_ultrassonic_sensors())\n",
    "    \n",
    "    def update_robot_frame_reading(self):\n",
    "        self.update_raw_reading()\n",
    "        for i, proximity in enumerate(self.data[\"raw_reading\"]):\n",
    "            if proximity == 5 or proximity < 0.1:\n",
    "                self.data[\"robot_frame_reading\"][i] = np.zeros(2)\n",
    "            else:\n",
    "                self.data[\"robot_frame_reading\"][i] = self.proximity_robot_frame(i+1,proximity).flatten()\n",
    "                \n",
    "    #Calcula o ponto no frame do robo, referente a leitura de cada sensor de proximidade\n",
    "    def proximity_robot_frame(self,sensorId, proximity):\n",
    "        index = sensorId -1\n",
    "        angulars = self.data[\"angles_rad\"][index]\n",
    "        #Matriz de rotação\n",
    "        rot_matrix = np.array([[math.cos(angulars),-math.sin(angulars)],[math.sin(angulars),math.cos(angulars)]])\n",
    "        #Rotacionando a leitura\n",
    "        distXY = np.dot(rot_matrix , np.array([[proximity],[0]]))\n",
    "        #Matriz de translação\n",
    "        posicao_sensor_x = self.data[\"positions\"][index][0]\n",
    "        posicao_sensor_y = self.data[\"positions\"][index][1]\n",
    "        transXY=np.array([[distXY[0][0]+posicao_sensor_x],[distXY[1][0]+posicao_sensor_y]])\n",
    "        return transXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined __toGlobal__ function to enable a later using. The function transform any _(x,y)_ point of robot reference into a global reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,robot_x],[0,1,robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),-math.sin(robot_ang),0],[math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_trans,T_rot)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    return res[0],res[1]\n",
    "def fromGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,-robot_x],[0,1,-robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),math.sin(robot_ang),0],[-math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_rot,T_trans)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    ang = np.arctan2(res[1],res[0])\n",
    "    return res[0],res[1], ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Kinematic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinematic_model:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "        \n",
    "        #Handles dos motores\n",
    "        ret1, self.motorLeft = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret2, self.motorRight = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        #Calcula distancia de eixo\n",
    "        res, left_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, lpos = vrep.simxGetObjectPosition(robot.clientID, left_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_streaming)\n",
    "        \n",
    "        res, right_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, rpos = vrep.simxGetObjectPosition(robot.clientID, right_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        ret,jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_streaming)\n",
    "       \n",
    "        # eixo\n",
    "        self.l = (abs(lpos[1]) + abs(rpos[1]))/2\n",
    "        \n",
    "        #Ao ser criado, coleta a referencia de zero do robo\n",
    "        pos = self.robot.get_current_position()\n",
    "        self.initial_pos_x = pos[0]\n",
    "        self.initial_pos_y = pos[1]\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        self.initial_orientation = orientation[2]\n",
    "\n",
    "        #Alem de mantermos a pose inicial, manteremos a pose atualizada do robo\n",
    "        self.enc_global_x = self.initial_pos_x\n",
    "        self.enc_global_y = self.initial_pos_y\n",
    "        self.enc_Theta = self.initial_orientation\n",
    "        self.gyro_global_x = self.initial_pos_x\n",
    "        self.gyro_global_y = self.initial_pos_y\n",
    "        self.gyro_Theta = self.initial_orientation\n",
    "        \n",
    "        #Lista de pontos para o caminho do robo\n",
    "        self.enc_path = []\n",
    "        self.gyro_path = []\n",
    "        self.time_path = []\n",
    "        self.true_path = []\n",
    "        self.update_paths()\n",
    "        \n",
    "        #inicializando a posição dos encoders\n",
    "        self.gyro_jL = self.current_encoder_left()\n",
    "        self.gyro_jR = self.current_encoder_right()\n",
    "        #inicializando a posição dos encoders\n",
    "        self.jL = self.current_encoder_left()\n",
    "        self.jR = self.current_encoder_right()\n",
    "        \n",
    "        #intervalo entre cada calculo\n",
    "        self.compute_interval = 0.1\n",
    "        self.previous_timestamp = 0\n",
    "        \n",
    "    def update_paths(self):\n",
    "        self.enc_path.append([self.enc_global_x, self.enc_global_y, self.enc_Theta])\n",
    "        self.gyro_path.append([self.gyro_global_x, self.gyro_global_y, self.gyro_Theta])\n",
    "\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        true_theta = orientation[2]\n",
    "        current_position = self.true_global_position()\n",
    "        self.true_path.append([current_position[0], current_position[1], true_theta])\n",
    "    \n",
    "    def true_global_position(self):\n",
    "        pos = self.robot.get_current_position()\n",
    "        return pos[0],pos[1]\n",
    "    \n",
    "    def enc_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.enc_Theta\n",
    "    \n",
    "    def gyro_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.gyro_Theta\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##Esta seção esta relacionada ao calculo da posição levando em consideração os encoders\n",
    "    def current_encoder_left(self):\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_buffer)\n",
    "        return jL\n",
    "    def current_encoder_right(self):\n",
    "        ret, jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_buffer)\n",
    "        return jR\n",
    "        \n",
    "    #Phi speed of rotation of wheels\n",
    "    def Xr(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Xr = (r*Phi_left/2) + (r*Phi_right/2)\n",
    "        return Xr\n",
    "    \n",
    "    def Theta_r(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Tr = r*Phi_right/(2*self.l) - r*Phi_left/(2*self.l) \n",
    "        return Tr\n",
    "        \n",
    "    def speed_model(self,Phi_right,Phi_left):\n",
    "        #Se formos considerar que o eixo das rodas do robo está deslocado do eixo x\n",
    "        #return np.array([self.Xr(Phi_right,Phi_left),self.Theta_r(Phi_right,Phi_left)*self.l2,self.Theta_r(Phi_right,Phi_left)])\n",
    "        return np.array([self.Xr(Phi_right,Phi_left),0,self.Theta_r(Phi_right,Phi_left)])\n",
    "        \n",
    "    def inverse_rotation_matrix(self, ang):\n",
    "        Trot = np.array([[math.cos(ang), -math.sin(ang), 0], [math.sin(ang), math.cos(ang), 0], [0,0,1]])\n",
    "        return Trot\n",
    "    \n",
    "    def locomotion_global(self, ang, Phi_right, Phi_left):\n",
    "        return np.dot(self.inverse_rotation_matrix(ang),self.speed_model(Phi_right,Phi_left))\n",
    "    \n",
    "    def compute_with_gyro(self):\n",
    "        dxR = self.current_encoder_right() - self.gyro_jR\n",
    "        dxL = self.current_encoder_left() - self.gyro_jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.gyro_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.gyro_global_x = self.gyro_global_x + qsi[0]\n",
    "        self.gyro_global_y = self.gyro_global_y + qsi[1]\n",
    "        \n",
    "        self.gyro_Theta = self.robot.read_gyroAngle()[2]\n",
    "        \n",
    "        #Atualiza a posição dos encoders\n",
    "        self.gyro_jR = self.current_encoder_right()\n",
    "        self.gyro_jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "    \n",
    "    def compute_with_encoder(self):\n",
    "        dxR = self.current_encoder_right() - self.jR\n",
    "        dxL = self.current_encoder_left() - self.jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.enc_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.enc_global_x = self.enc_global_x + qsi[0]\n",
    "        self.enc_global_y = self.enc_global_y + qsi[1]\n",
    "        \n",
    "        self.enc_Theta = self.enc_Theta + qsi[2]\n",
    "\n",
    "\n",
    "        #Atualiza a posição dos encoders\n",
    "        self.jR = self.current_encoder_right()\n",
    "        self.jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "\n",
    "    def turnGlobal(self, input_ang):\n",
    "        orientation = self.robot.get_current_orientation()[2]\n",
    "        ang = -input_ang\n",
    "            \n",
    "        vel = 0.3\n",
    "        new_orientation = ang\n",
    "        if (new_orientation > math.pi):\n",
    "            new_orientation = new_orientation -2*math.pi\n",
    "        elif (new_orientation < -math.pi):\n",
    "            new_orientation = new_orientation +2*math.pi\n",
    "\n",
    "        if (new_orientation > 0) :\n",
    "            vel=-vel\n",
    "        self.robot.set_right_velocity(vel)\n",
    "        self.robot.set_left_velocity(-vel)\n",
    "\n",
    "        return vel, -vel\n",
    "    \n",
    "    def move(self,Phi_right, Phi_left,seconds): #velocidade em rad/s\n",
    "        #Vamos fixar um tempo de 500ms para computar as distâncias\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            self.robot.set_right_velocity(Phi_right)\n",
    "            self.robot.set_left_velocity(Phi_left)\n",
    "            time.sleep(self.compute_interval)\n",
    "            self.compute_with_encoder()\n",
    "            self.compute_with_gyro()\n",
    "            self.update_paths()\n",
    "        self.robot.stop()\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def ICR_left(self, Phi_left, R, seconds):\n",
    "        Phi_right = Phi_left*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_left Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "    \n",
    "    def ICR_right(self, Phi_right, R, seconds):\n",
    "        Phi_left = Phi_right*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_right Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "        \n",
    "    def plot_paths(self):\n",
    "        gyro_path = np.array(self.gyro_path)\n",
    "        enc_path = np.array(self.enc_path)\n",
    "        time_path = np.array(self.time_path)\n",
    "        true_path = np.array(self.true_path)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "        ax.plot(enc_path[:,0], enc_path[:,1], 1, c='g', label='odometry')\n",
    "        ax.plot(gyro_path[:,0], gyro_path[:,1], 1, c='b', label='odometry + gyro')\n",
    "        ax.plot(true_path[:,0], true_path[:,1], 1, c='r', label='ground truth')\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud():\n",
    "    def __init__(self, robot, us_sensors, laser_sensor):\n",
    "        self.grid_map = None\n",
    "        self.robot = robot\n",
    "        self.us_sensors = us_sensors\n",
    "        self.laser_sensor = laser_sensor\n",
    "        self.res = 0.05\n",
    "        \n",
    "        self.ultrassonic_points = []\n",
    "        self.laser_points = []\n",
    "        self.robot_points = []\n",
    "        \n",
    "        self.gridMapPosPoints = []\n",
    "    \n",
    "    def update(self):\n",
    "        #Insere posição atual do robo\n",
    "        robot_x = self.robot.get_current_position()[0]\n",
    "        robot_y = self.robot.get_current_position()[1]\n",
    "        robot_ang = self.robot.get_current_orientation()[2]\n",
    "        \n",
    "        self.robot_points.append([robot_x,robot_y])\n",
    "\n",
    "        #Atualiza a leitura do laser e insere na nuvem de pontos\n",
    "        self.laser_sensor.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.laser_sensor.laser_x, self.laser_sensor.laser_y):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.laser_points.append([x,y])\n",
    "\n",
    "        #Atualiza a leitura do ultrassonico e insere na nuvem de pontos\n",
    "        self.us_sensors.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.us_sensors.data['robot_frame_reading'][:,0], self.us_sensors.data['robot_frame_reading'][:,1]):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.ultrassonic_points.append([x,y])\n",
    "    \n",
    "    def plot_point_cloud(self):\n",
    "        #Convertendo a nuvem de pontos em um array\n",
    "        ultrassonic_point_array = np.array(self.ultrassonic_points)\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        robot_path = np.array(self.robot_points)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        #posição do centro do robo\n",
    "        ax[0].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[0].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax[0].scatter(ultrassonic_point_array[:,0],ultrassonic_point_array[:,1], 10, c='magenta', marker='.')\n",
    "\n",
    "        #posição do centro do robo\n",
    "        ax[1].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[1].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor laser\n",
    "        ax[1].scatter(laser_point_array[:,0],laser_point_array[:,1], 10, c='r', marker='.')\n",
    "\n",
    "        plt.show()\n",
    "          \n",
    "    def set_resolution(self, resolution):\n",
    "        self.res = resolution\n",
    "        \n",
    "    def compute_grid_ocupation(self):\n",
    "        xyreso = self.res  # x-y grid resolution\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        ox = laser_point_array[:,0]\n",
    "        oy = laser_point_array[:,1]\n",
    "        self.pmap, self.minx, self.maxx, self.miny, self.maxy, self.xyreso, self.centix, self.centiy = \\\n",
    "        lg.generate_ray_casting_grid_map(ox, oy, xyreso, True)\n",
    "        self.gridwidth = np.array(self.pmap).shape[0]\n",
    "        self.gridheight = np.array(self.pmap).shape[1]\n",
    "        self.grid_map = gm.GridMap( self.gridwidth, self.gridheight, self.res,\n",
    "                 self.centix, self.centiy, init_val= self.pmap)\n",
    "        \n",
    "    def get_idx_from_pos(self, x, y):\n",
    "        ix = int(round((x - self.minx) / self.xyreso)) # x coordinate of the the occupied area\n",
    "        iy = int(round((y - self.miny) / self.xyreso)) # y coordinate of the the occupied area\n",
    "        return ix, iy\n",
    "    \n",
    "    def get_pos_from_idx(self, idx, idy):\n",
    "        x = round((idx*self.xyreso) + self.minx, 2)\n",
    "        y = round((idy*self.xyreso) + self.miny, 2)\n",
    "        return x, y\n",
    "            \n",
    "    def plot_grid_ocupation(self):\n",
    "        plt.figure(figsize=(20,8))\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(self.pmap.T, cmap = \"PiYG_r\") \n",
    "        plt.clim(-0.4, 1.4)\n",
    "        plt.gca().set_xticks(np.arange(-.5, self.gridwidth, 1), minor = True)\n",
    "        plt.gca().set_yticks(np.arange(-.5, self.gridheight, 1), minor = True)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(True, which=\"minor\", color=\"w\", linewidth = .6, alpha = 0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    def update_grid_map_pos_points(self):\n",
    "        self.gridMapPosPoints = []\n",
    "        indexes = np.where(self.pmap == 1)\n",
    "        for index in range(len(indexes[0])):\n",
    "            idx_x = indexes[0][index]\n",
    "            idx_y = indexes[1][index]\n",
    "            self.gridMapPosPoints.append(self.get_pos_from_idx(idx_x, idx_y))\n",
    "    \n",
    "    def plot_grid_map_pos_points(self):\n",
    "        point_array = np.array(self.gridMapPosPoints)\n",
    "        plt.scatter(point_array[:,0],point_array[:,1], 10, c='r', marker='.')\n",
    "        plt.axis('equal')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - AvoidObstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behaviour was implemented using Fuzzy logic. In other to correctlly demonstrate the behaviour, a simple wandering algorithim is simulated bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bellow Fuzzyfication function was implemented, receiving as its input the reading of the sonar sensors. The eight frontal sonar sensors was classified into 3 groups: left sensors (__x_l:__ 1 to 3 sensors); forward (__x_f:__ 3 to 6 sensors) and; right (__x_r:__ 6 to 8 sensors). For fuzzification we adopted the minimal value each one.\n",
    "\n",
    "We choose 0.1m as __near__ and values between 0.1 and 0.4m as __almost near__. Far value was considered irrelevant in results.\n",
    "\n",
    "The function print a graphic result if you set the __\\_print__ value to __1__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sensor_fuzzyfication(frontal_sensors,_print=0, _near=0.15, _almost_near=0.5) :\n",
    "    x_v = np.arange(-0.1, 5.1, 0.01)\n",
    "    t_close = [-0.1, -0.1, _near, _almost_near]\n",
    "    mfx_close = fuzz.trapmf(x_v, t_close)\n",
    "    #t_far = [0.3, .55, 5, 5]                /// Results are irrelevant\n",
    "    #mfx_far = fuzz.trapmf(x_v, t_far)       /// Results are irrelevant\n",
    "    x_l = np.array([round(min(frontal_sensors[:2]))])    # Left sensors\n",
    "    x_f = np.array([min(frontal_sensors[3:5])])          # Forward Sensors\n",
    "    x_r = np.array([round(min(frontal_sensors[6:8]),1)]) # Right sensors\n",
    "    y_l = np.array([-1]) # Null value\n",
    "    y_f = np.array([-1]) # Null value\n",
    "    y_r = np.array([-1]) # Null value\n",
    "    if(x_l[0] < _almost_near) :\n",
    "        y_l = fuzz.trapmf(x_l, t_close) # Return fuzzy value for left sensors\n",
    "    if(x_f[0] < _almost_near) :\n",
    "        y_f = fuzz.trapmf(x_f, t_close) # Return fuzzy value for forward sensors\n",
    "    if(x_r[0] < _almost_near) :\n",
    "        y_r = fuzz.trapmf(x_r, t_close) # Return fuzzy value for right sensors\n",
    "    \n",
    "    # Just for print mode\n",
    "    if (_print > 0) : \n",
    "        plt.plot(x_v, mfx_close,label=\"Near\")\n",
    "        colors = ['tab:black','tab:cyan','tab:purple','tab:green','tab:red','tab:brown','tab:olive','tab:gray','tab:pink']\n",
    "        if(x_l[0] < 1) : plt.vlines(x_l, 0, y_l, label=\"min_left\",color=colors[1]); print(\"Left sensors fuzzyfication: \"+str(y_l[0]))\n",
    "        if(x_f[0] < 1) : plt.vlines(x_f, 0, y_f, label=\"min_forward\",color=colors[2]); print(\"Forward sensors fuzzyfication: \"+str(y_f[0]))\n",
    "        if(x_r[0] < 1) : plt.vlines(x_r[0], 0, y_r, label=\"min_right\",color=colors[3]); print(\"Right sensors fuzzyfication: \"+str(y_r[0]))\n",
    "        plt.ylabel('Fuzzy value')\n",
    "        plt.xlabel('Proximity (m)')\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "        plt.legend(loc=1)\n",
    "        plt.draw()\n",
    "        plt.pause(0.05)\n",
    "    \n",
    "    # Return useful value: used X range; Y result values and; near trapezoidal.\n",
    "    return x_v, y_l, y_f, y_r, t_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object avoidance will be given by the defuzzyfication function bellow, acting in oposition to the proximitiy sensor. The function starts an initial verification if the frontal sensors minimal value is grater than 0.4m (our almost near value). In this case it returns the angular velocity equal 2 to both wheels. Else, it goes to defuzzification angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoidByDefuzzyfication(frontal_sensors,fuzzy_results, _print=0) :\n",
    "    if (min(frontal_sensors) > fuzzy_results[4][3]) : # in case all frontal sensor is grater than almost near\n",
    "        velL = 2\n",
    "        velR = 2\n",
    "        return velL, velR           # Stop function and return equal values. \n",
    "                                    # This condition avoid a defuzzy error obtaining a null crisp value\n",
    "    y_v = np.arange(-95, 95, 1)\n",
    "    x_v = fuzzy_results[0]\n",
    "\n",
    "    mfy_left = fuzz.trimf(y_v, [-95, -95,-10])       # Values to get  a left collision probabillity\n",
    "    mfy_forward = fuzz.trapmf(y_v, [-60,-30, 30,60]) # Values to get  a forward collision probabillity\n",
    "    mfy_right = fuzz.trimf(y_v, [10,95,95])          # Values to get  a right collision probabillity\n",
    "\n",
    "    proximityL = ctrl.Antecedent(x_v, 'proximityL')\n",
    "    proximityR = ctrl.Antecedent(x_v, 'proximityR')\n",
    "    proximityF = ctrl.Antecedent(x_v, 'proximityF')\n",
    "    prob = ctrl.Consequent(y_v, 'Collision')         # Collision probabillity\n",
    "\n",
    "    proximity = fuzz.trapmf(x_v,[-0.1, -0.1, fuzzy_results[4][2], fuzzy_results[4][3]])\n",
    "    proximityL['near'] = proximity\n",
    "    proximityR['near'] = proximity\n",
    "    proximityF['near'] = proximity\n",
    "    prob['Left'] = mfy_left\n",
    "    prob['Forward'] = mfy_forward\n",
    "    prob['Right'] = mfy_right\n",
    "\n",
    "\n",
    "    # This method define 3 rules to get our fuzzy set\n",
    "    rule1 = ctrl.Rule(proximityL['near'] , prob['Left'])\n",
    "    rule2 = ctrl.Rule(proximityF['near'] , prob['Forward'])\n",
    "    rule3 = ctrl.Rule(proximityR['near'], prob['Right'])\n",
    "\n",
    "    vel_ctrl = ctrl.ControlSystem([rule1, rule2, rule3]) # Defuzzy rules for collision possibility\n",
    "    vel = ctrl.ControlSystemSimulation(vel_ctrl)\n",
    "\n",
    "    vel.input['proximityL'] = min(frontal_sensors[:3])\n",
    "    vel.input['proximityR'] = min(frontal_sensors[5:8])\n",
    "    vel.input['proximityF'] = min(frontal_sensors[2:6])\n",
    "\n",
    "    if (_print > 0) :\n",
    "        # Print minimal sensor distances\n",
    "        print(\"Distance Left: \"+str(min(frontal[:3])))\n",
    "        print(\"Distance Forward: \"+str(min(frontal[2:6])))\n",
    "        print(\"Distance Right: \"+str(min(frontal[5:8])))\n",
    "\n",
    "    vel_output = 1\n",
    "\n",
    "    if (min(frontal_sensors) <= 1):\n",
    "        vel.compute()\n",
    "        # Using Mamdani's method we output a fuzzy set \n",
    "        # and obtain a crisp value from centroid\n",
    "        \n",
    "        vel_output = round(vel.output['Collision'])   # Collision angle probabillity crisp value\n",
    "        Collision = \"Collision: \"+str(vel_output)+\"°\"\n",
    "    else: Collision = \"No collision\"\n",
    "    if (_print > 0) :\n",
    "        print(Collision)\n",
    "        prob.view(sim=vel)\n",
    "    \n",
    "    x_w = np.arange(-100,100,0.1)\n",
    "    wlv = [-100, -100,0,50]    # Fuzzify crisp value to obtain left wheel angular velocity\n",
    "    wrv = [0,10,100,100]       # Fuzzify crisp value to obtain right wheel angular velocity\n",
    "    # We use diferent trapezoidal graphics for the wheels to avoid equal speed in frontal collision possibility\n",
    "    \n",
    "    x = np.array([vel_output])\n",
    "    y_l=fuzz.trapmf(x, wlv)    # Fuzzy value for left wheel\n",
    "    y_r=fuzz.trapmf(x, wrv)    # Fuzzy value for right wheel\n",
    "    if (_print > 0) :\n",
    "        #Print graphics\n",
    "        WheelL = fuzz.trapmf(x_w, wlv)\n",
    "        WheelR = fuzz.trapmf(x_w, wrv)\n",
    "        plt.plot(x_w, WheelL,label=\"Wheel Left\")\n",
    "        plt.plot(x_w, WheelR,label=\"Wheel Right\")\n",
    "        plt.vlines(x, 0, y_l, label=\"Collision\")\n",
    "        plt.vlines(x, 0, y_r)\n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "        plt.pause(0.05)\n",
    "        print(\"Wheel left angular velocity: \"+str((y_l[0]-0.5)/0.25))\n",
    "        print(\"Wheel right angular velocity: \"+str((y_r[0]-0.5)/0.25))\n",
    "    \n",
    "    velL = (y_l[0]-0.5)/0.5    #Convert Fuzzy value into angular speed for left wheel\n",
    "    velR = (y_r[0]-0.5)/0.5    #Convert Fuzzy value into angular speed for right wheel\n",
    "\n",
    "    return velL, velR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Go To Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of moving forward on robot current direction, we could implement a behaviour to Go to a specific point on the global reference.\n",
    "The implementation is given by the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_diretion(robot, us_sensors, go_point_x, go_point_y, _print=0):\n",
    "    \n",
    "    # global position of robot\n",
    "    robot_x = robot.get_current_position()[0]\n",
    "    robot_y = robot.get_current_position()[1]\n",
    "    robot_ang = robot.get_current_orientation()[2]\n",
    "    \n",
    "    # relative vector to goal\n",
    "    vec_x_go = go_point_x - robot_x\n",
    "    vec_y_go = go_point_y - robot_y\n",
    "    \n",
    "    # angle between position and goal vector\n",
    "    # vector origin\n",
    "    T_trans = np.array([[vec_x_go],[vec_y_go]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),math.sin(robot_ang)],[-math.sin(robot_ang),math.cos(robot_ang)]])\n",
    "    T = np.dot(T_rot,T_trans)\n",
    "    \n",
    "    ang = math.atan2(T[0],T[1]) - (math.pi/2)\n",
    "    if (ang > math.pi) :\n",
    "        ang = ang - 2*math.pi\n",
    "    if (ang < -math.pi) :\n",
    "        ang = ang + 2*math.pi\n",
    "\n",
    "    if (_print==0):\n",
    "        print(\"ang:\")\n",
    "        print(ang)\n",
    "        print(\"ang robot:\")\n",
    "        print(robot_ang)\n",
    "    \n",
    "        # plot\n",
    "        plt.plot([0,0],[-7.5,7.5], color='g')\n",
    "        plt.plot([-7.5,7.5], [0,0], color='r')\n",
    "        origin = [robot_x, robot_y]\n",
    "        plt.quiver(*origin, vec_x_go, vec_y_go, color=['b'])\n",
    "\n",
    "        plt.axis([-7.5,7.5,-7.5,7.5])\n",
    "        plt.show()\n",
    "        \n",
    "    return ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Behaviour Coordenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planning():\n",
    "\n",
    "    def _init_(self):\n",
    "        self.pmap = [[0,0],[0,0]]\n",
    "\n",
    "    def find_zeros(self, pmap):\n",
    "        l = 0\n",
    "        c = 0\n",
    "        zero = []\n",
    "        pmap = np.array(pmap)\n",
    "        for line in pmap:\n",
    "            c = 0\n",
    "            for column in line:\n",
    "                if (column == 0):\n",
    "                    zero.append([l,c])\n",
    "                c = c + 1\n",
    "            l = l + 1\n",
    "        return zero\n",
    "    \n",
    "    def planning_path(self, pmap):\n",
    "        path_points = []\n",
    "        zero = self.find_zeros(pmap)\n",
    "        last_point = zero[0] #define o ínicio do caminho\n",
    "        l = zero[0][0]\n",
    "        c = zero[0][1]\n",
    "        numrows = len(pmap)\n",
    "        numcols = len(pmap[0])\n",
    "        for point in zero:\n",
    "            if (point[0] != l):\n",
    "                path_points.append(last_point)\n",
    "                l = point[0]\n",
    "                c = point[1]\n",
    "                path_points.append([l,c])\n",
    "            last_point = point\n",
    "        ry = []\n",
    "        rx = []\n",
    "        \n",
    "        for point in path_points:\n",
    "            rx.append(point[0])\n",
    "            ry.append(point[1])\n",
    "        return rx, ry\n",
    "\n",
    "    def get_path(self, pmap):\n",
    "        rx, ry = self.planning_path(pmap)#rx, ry = self.planning_path(pmap[::6])\n",
    "        correct_rx = rx#correct_rx = np.array(rx)*6\n",
    "        ax, fig = plt.subplots(1,1)\n",
    "        ax.clf()\n",
    "        plt.cla()\n",
    "        plt.imshow(np.transpose(pmap), cmap = \"PiYG_r\")\n",
    "        plt.plot(correct_rx, ry, label='path')\n",
    "        plt.plot(correct_rx[0], ry[0], marker='o', color='b', label='start')\n",
    "        plt.plot(correct_rx[-1],ry[-1], marker='o', color='r', label='end')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        return correct_rx, ry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Gyro connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.point_cloud = PointCloud(self.robot, self.us_sensors, self.laser_sensors)\n",
    "        self.point_cloud.update()\n",
    "        self.compute_interval = 0.5\n",
    "        \n",
    "        self.px = [] \n",
    "        self.py = []\n",
    "        self.plannedStep = 0\n",
    "        self.planning_reso = 0.46\n",
    "   \n",
    "        self.go_x = 0\n",
    "        self.go_y = 0\n",
    "        \n",
    "        self.tries = 0\n",
    "    \n",
    "    # Find direction for the destination point\n",
    "    def direction(self):\n",
    "        return give_diretion(self.robot, self.us_sensors, self.go_x, self.go_y, 1)\n",
    "        \n",
    "    # Set destination point\n",
    "    def setGoal(self, x, y):\n",
    "        self.go_x = x\n",
    "        self.go_y = y\n",
    "        \n",
    "    def calculateDistance(self, x1,y1,x2,y2):\n",
    "        dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        return dist\n",
    "        \n",
    "    # Check if the robot has reached destination\n",
    "    def checkFinal(self):\n",
    "        curr_x, curr_y = self.kinematicModel.true_global_position()\n",
    "        dist = self.calculateDistance(curr_x, curr_y, self.go_x, self.go_y)\n",
    "        return dist < 0.2\n",
    "    \n",
    "    def checkCorrectDirection(self):\n",
    "        go_direction = self.direction()\n",
    "        robot_direction = self.robot.get_current_orientation()[2]\n",
    "        direction = go_direction - robot_direction\n",
    "        return (abs(go_direction) < (math.pi/90))\n",
    "    \n",
    "    # Avoid obstacles using fuzzy logic\n",
    "    def fuzzyControl(self):\n",
    "        frontal = self.robot.read_ultrassonic_sensors()[:8]\n",
    "        fuzzy = sensor_fuzzyfication(frontal,0,0.01,0.5) # Call function fuzzy and set near=0.05 and almost_near=0.2\n",
    "        avoid = avoidByDefuzzyfication(frontal,fuzzy)\n",
    "        return avoid[0], avoid[1]\n",
    "    \n",
    " \n",
    "    # Subsumption behavior controller\n",
    "    def control(self):\n",
    "        vel_l = 0\n",
    "        vel_r = 0\n",
    "    \n",
    "        min_frontal = np.min(np.array(self.robot.read_ultrassonic_sensors()[:8]))\n",
    "        min_rear = np.min(np.array(self.robot.read_ultrassonic_sensors()[10:14]))\n",
    "        all_sensors = np.min(np.array(self.robot.read_ultrassonic_sensors()))\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        \n",
    "        curr_x, curr_y = self.kinematicModel.true_global_position()\n",
    "        pos = str([curr_x, curr_y])+\" to \"+str([self.go_x, self.go_y])\n",
    "        \n",
    "        #1st Priority: React rear and frontal collision possibility\n",
    "        if (min_rear < 0.2) :\n",
    "            vel_l, vel_r = [2.0,2.0]\n",
    "            pText = \"React rear collision. Position: \"+pos\n",
    "        elif (min_frontal < 0.2) :\n",
    "            vel_l, vel_r = [-2.0,-2.0]\n",
    "            pText = \"React front collision. Position: \"+pos\n",
    "        #2nd Priority: Avoid Obstacle\n",
    "        elif (min_frontal <= 0.40):\n",
    "            vel_l, vel_r = self.fuzzyControl()\n",
    "            vel_l = vel_l * 1.5\n",
    "            vel_r = vel_r * 1.5\n",
    "            pText = \"Avoid Obstacle. Position:  \"+pos\n",
    "            self.tries = self.tries + 1\n",
    "        #3rd Priority: Turn to destination direction\n",
    "        elif (not self.checkCorrectDirection() and (all_sensors > 0.4)):\n",
    "            direct = self.direction()\n",
    "            vel_l, vel_r = self.kinematicModel.turnGlobal(direct)\n",
    "            vel_l = vel_l/2\n",
    "            vel_r = vel_r/2\n",
    "            pText = \"Turn Ang: {} Robot: {}\".format(direct,self.robot.get_current_orientation()[2])\n",
    "        #4th Priority: Go Forward\n",
    "        else:\n",
    "            vel_l = 2\n",
    "            vel_r = 2\n",
    "            pText = \"Go Forward. Position: \"+pos\n",
    "        sys.stdout.write(\"\\r\" + pText)\n",
    "        sys.stdout.flush()\n",
    "        return vel_l, vel_r\n",
    "\n",
    "    def start(self, seconds):\n",
    "        Errors = 0\n",
    "        self.next_planned_step()\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            Phi_l, Phi_r = self.control()\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            if (self.checkFinal() or self.tries > 50) :\n",
    "                self.next_planned_step()\n",
    "                Errors = Errors + 1\n",
    "                if (self.plannedStep == len(self.px) - 1):\n",
    "                    self.robot.stop()\n",
    "                    print(\"You have reached your destination! Error points: \")\n",
    "                    print(Errors)\n",
    "                    self.kinematicModel.plot_paths()\n",
    "                    break\n",
    "    \n",
    "    def wandering_control(self, frontal):\n",
    "        fuzzy = sensor_fuzzyfication(frontal)\n",
    "        avoid = avoidByDefuzzyfication(frontal,fuzzy)    # Defuzzyfication\n",
    "        return avoid[0], avoid[1]\n",
    "    \n",
    "    def start_wander(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)): # Repeat avoidance each 0.2s (self.compute_interval)\n",
    "            Phi_l, Phi_r = self.wandering_control(self.robot.read_ultrassonic_sensors()[:8]) # Get angular speed from avoidance function\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)           # Apply angular speed to kinematic model\n",
    "            self.point_cloud.update()\n",
    "    \n",
    "    def next_planned_step(self):\n",
    "        self.setGoal(self.px[self.plannedStep], self.py[self.plannedStep])\n",
    "        print(\"Next Planned step \", self.plannedStep, \"/\", len(self.px), self.px[self.plannedStep], self.py[self.plannedStep])\n",
    "        self.plannedStep = self.plannedStep + 1\n",
    "        self.tries = 0\n",
    "        \n",
    "    def plot_planning(self):\n",
    "        plot_planning(self.px, self.py, self.planning_reso)\n",
    "    \n",
    "    def do_planning(self):\n",
    "        plan_plot = Planning()\n",
    "        x, y = plan_plot.get_path(self.point_cloud.pmap)\n",
    "        arr = np.array([ self.point_cloud.get_pos_from_idx(x[i], y[i]) for i in range(len(x))]).T\n",
    "        self.px = arr[0]\n",
    "        self.py = arr[1]\n",
    "\n",
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.start_wander(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.kinematicModel.plot_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.point_cloud.res = 0.46\n",
    "mr.point_cloud.compute_grid_ocupation()\n",
    "mr.point_cloud.plot_grid_ocupation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mr.do_planning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.start(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start _GotoGoal Subsumption Behavior_ without set a destination point. Thus robot goes to Global origin (0,0). For set a point, write __mr.setGoal(x,y)__ bellow before start function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Video URL:__ http://youtube.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
