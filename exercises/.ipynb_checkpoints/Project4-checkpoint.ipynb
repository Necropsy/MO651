{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalho 4 - Robótica Movel - MO651\n",
    "#### __Professor(a):__ _Esther Luna Columbini_ <br>\n",
    "__Alunos:__ <br>\n",
    "_Tito Barbosa Rezende_              __RA:__ 025327<br>\n",
    "_João Paulo_                        __RA:__ 229322<br>\n",
    "_Elcio Pereira de Souza Junior_     __RA:__ 262952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisitos\n",
    "\n",
    "Instalação das bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install sklearn\n",
    "%pip install pwlf\n",
    "%pip install gpyopt\n",
    "%pip install pypng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.insert(0, '../src')\n",
    "from robot import Robot\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "import numpy as np\n",
    "import vrep\n",
    "import math\n",
    "import multiprocessing\n",
    "import random\n",
    "from datetime import datetime\n",
    "import lidar_to_grid_map as lg\n",
    "import grid_map_lib as gm\n",
    "import operator\n",
    "import asyncio\n",
    "import png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo objeto robô\n",
    "\n",
    "Nos próximos passos será instanciado o objeto robô, este será utilizado durante todo o projeto. Também serão realizados uma série de testes de conexão com a API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Gyro connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.read_gyroAngle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.set_right_velocity(-5)\n",
    "time.sleep(10)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Cinemático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Laser\n",
    "\n",
    "Nesta etapa definimos a classe para leitura dos dados que serão obtidos pelo sensor laser, e realizamos uma verificação sobre a obtenção destes dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser_sensor:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "\n",
    "    def update_robot_frame_reading(self):\n",
    "        laser_flatten_readings = np.array(self.robot.read_laser())\n",
    "        laser_readings = laser_flatten_readings.reshape((len(laser_flatten_readings)//3, 3))\n",
    "        self.laser_x = laser_readings[:,0]\n",
    "        self.laser_y = laser_readings[:,1]\n",
    "\n",
    "    def plot_laser_robot_frame(self):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     #posição dos feixes laser\n",
    "#     ax.scatter(laser_sensor.laser_x, laser_sensor.laser_y, 3, c='g', marker='o')\n",
    "#     #posição do centro do robo\n",
    "#     ax.scatter(0, 0, 40, c='b', marker='o')\n",
    "#     plt.show()\n",
    "        ox = self.laser_x\n",
    "        oy = self.laser_y\n",
    "        plt.figure(figsize=(6,10))\n",
    "        plt.plot([oy, np.zeros(np.size(oy))], [ox, np.zeros(np.size(oy))], \"ro-\") # lines from 0,0 to the \n",
    "        plt.axis(\"equal\")\n",
    "        bottom, top = plt.ylim()  # return the current ylim\n",
    "        plt.ylim((top, bottom)) # rescale y axis, to match the grid orientation\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_grid_fill(self):\n",
    "        xyreso = 0.02  # x-y grid resolution\n",
    "        #yawreso = math.radians(3.1)  # yaw angle resolution [rad]\n",
    "        \n",
    "        ox = self.laser_x\n",
    "        oy = self.laser_y\n",
    "        pmap, minx, maxx, miny, maxy, xyreso = lg.generate_ray_casting_grid_map(ox, oy, xyreso, False)\n",
    "        xyres = np.array(pmap).shape\n",
    "        plt.figure(figsize=(20,8))\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(pmap, cmap = \"PiYG_r\") \n",
    "        plt.clim(-0.4, 1.4)\n",
    "        plt.gca().set_xticks(np.arange(-.5, xyres[1], 1), minor = True)\n",
    "        plt.gca().set_yticks(np.arange(-.5, xyres[0], 1), minor = True)\n",
    "        plt.grid(True, which=\"minor\", color=\"w\", linewidth = .6, alpha = 0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "         \n",
    "    \n",
    "laser_sensor = Laser_sensor(robot)\n",
    "laser_sensor.update_robot_frame_reading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação dos dados brutos coletados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_sensor.plot_laser_robot_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_sensor.plot_grid_fill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mudar a posição do robo e ler novamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Ultrassônico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a leitura correta dos sensores de proximidade, precisamos transformar a leitura do sensor em um ponto _(x,y)_ em relação ao frame do robo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Us_sensor:\n",
    "    def __init__(self,robot):\n",
    "        orientation_angles = np.array([90,50,30,10,-10,-30,-50,-90,-90,-130,-150,-170,170,150,130,90])\n",
    "        orientation_rad = np.radians(orientation_angles)\n",
    "        self.data = {\n",
    "        \"prefix\" : \"Pioneer_p3dx_ultrasonicSensor\",\n",
    "        \"ids\" : np.arange(1,17,1), \"handles\" : np.zeros(16, dtype=int), \n",
    "        \"positions\" :  np.zeros((16,3),dtype=float),\n",
    "        \"angles_deg\": orientation_angles,\n",
    "        \"angles_rad\": orientation_rad,\n",
    "        \"raw_reading\": np.zeros(16),\n",
    "        \"robot_frame_reading\": np.zeros((16,2),dtype=float)\n",
    "        }\n",
    "        self.robot = robot\n",
    "        \n",
    "        for i,sensor_i in enumerate(self.data['ids']):\n",
    "            ret,handle = vrep.simxGetObjectHandle(self.robot.clientID, self.data['prefix'] + str(sensor_i), vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['handles'][i] = handle\n",
    "            ret, pos = vrep.simxGetObjectPosition(self.robot.clientID, handle, self.robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            #ret, ang = vrep.simxGetObjectOrientation(robot.clientID, handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['positions'][i,:] = pos\n",
    "            #ultrassonic_sensors[sensor_i,4:7] = ang\n",
    "    \n",
    "    def update_raw_reading(self):\n",
    "        self.data[\"raw_reading\"] = np.array(self.robot.read_ultrassonic_sensors())\n",
    "    \n",
    "    def update_robot_frame_reading(self):\n",
    "        self.update_raw_reading()\n",
    "        for i, proximity in enumerate(us_sensors.data[\"raw_reading\"]):\n",
    "            if proximity == 5 or proximity < 0.1:\n",
    "                self.data[\"robot_frame_reading\"][i] = np.zeros(2)\n",
    "            else:\n",
    "                self.data[\"robot_frame_reading\"][i] = self.proximity_robot_frame(i+1,proximity).flatten()\n",
    "                \n",
    "        #toRobotFrame = lambda sensorId,proximity: self.proximity_robot_frame(sensorId,proximity)\n",
    "        #self.data[\"robot_frame_reading\"] = toRobotFrame(range(1,17,1),us_sensors.data[\"raw_reading\"])\n",
    "    \n",
    "    #Calcula o ponto no frame do robo, referente a leitura de cada sensor de proximidade\n",
    "    def proximity_robot_frame(self,sensorId, proximity):\n",
    "        index = sensorId -1\n",
    "        angulars = self.data[\"angles_rad\"][index]\n",
    "        #Matriz de rotação\n",
    "        rot_matrix = np.array([[math.cos(angulars),-math.sin(angulars)],[math.sin(angulars),math.cos(angulars)]])\n",
    "        #Rotacionando a leitura\n",
    "        distXY = np.dot(rot_matrix , np.array([[proximity],[0]]))\n",
    "        #Matriz de translação\n",
    "        posicao_sensor_x = self.data[\"positions\"][index][0]\n",
    "        posicao_sensor_y = self.data[\"positions\"][index][1]\n",
    "        transXY=np.array([[distXY[0][0]+posicao_sensor_x],[distXY[1][0]+posicao_sensor_y]])\n",
    "        return transXY\n",
    "    \n",
    "    def plot_us_robot_frame(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        #posição dos sensores US\n",
    "        ax.scatter(self.data['positions'][:,0], self.data['positions'][:,1], 10, c='r', marker='o')\n",
    "        #posição do centro do robo\n",
    "        ax.scatter(0, 0, 40, c='b', marker='o')\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax.scatter(self.data['robot_frame_reading'][:,0], self.data['robot_frame_reading'][:,1], 10, c='black', marker='.')\n",
    "        plt.show()\n",
    "\n",
    "us_sensors = Us_sensor(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos uma função _toGlobal_ (para termos um melhor reuso de código), basicamente a função transforma um ponto qualquer _(x,y)_ que esteja na referência do robô e o leva para a referência global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,robot_x],[0,1,robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),-math.sin(robot_ang),0],[math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_trans,T_rot)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    return res[0],res[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Cinemático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado o movimento do robo, como determinar sua posição e orientação no frame global?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinematic_model:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "        \n",
    "        #Handles dos motores\n",
    "        ret1, self.motorLeft = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret2, self.motorRight = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        #Calcula distancia de eixo\n",
    "        res, left_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, lpos = vrep.simxGetObjectPosition(robot.clientID, left_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_streaming)\n",
    "        \n",
    "        res, right_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, rpos = vrep.simxGetObjectPosition(robot.clientID, right_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        ret,jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_streaming)\n",
    "       \n",
    "        # eixo\n",
    "        self.l = (abs(lpos[1]) + abs(rpos[1]))/2\n",
    "        \n",
    "        #Ao ser criado, coleta a referencia de zero do robo\n",
    "        pos = self.robot.get_current_position()\n",
    "        self.initial_pos_x = pos[0]\n",
    "        self.initial_pos_y = pos[1]\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        self.initial_orientation = orientation[2]\n",
    "\n",
    "        #Alem de mantermos a pose inicial, manteremos a pose atualizada do robo\n",
    "        self.enc_global_x = self.initial_pos_x\n",
    "        self.enc_global_y = self.initial_pos_y\n",
    "        self.enc_Theta = self.initial_orientation\n",
    "        \n",
    "        self.time_global_x = self.initial_pos_x\n",
    "        self.time_global_y = self.initial_pos_y\n",
    "        self.time_Theta = self.initial_orientation\n",
    "        \n",
    "        #Lista de pontos para o caminho do robo\n",
    "        self.enc_path = []\n",
    "        self.time_path = []\n",
    "        self.true_path = []\n",
    "        self.update_paths()\n",
    "        \n",
    "        #inicializando a posição dos encoders\n",
    "        self.jL = self.current_encoder_left()\n",
    "        self.jR = self.current_encoder_right()\n",
    "        \n",
    "        #intervalo entre cada calculo\n",
    "        self.compute_interval = 0.1\n",
    "        self.previous_timestamp = 0\n",
    "        \n",
    "    def update_paths(self):\n",
    "        self.enc_path.append([self.enc_global_x, self.enc_global_y, self.enc_Theta])\n",
    "        self.time_path.append([self.time_global_x, self.time_global_y, self.time_Theta])\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        true_theta = orientation[2]\n",
    "        current_position = self.true_global_position()\n",
    "        self.true_path.append([current_position[0], current_position[1], true_theta])\n",
    "    \n",
    "    def true_global_position(self):\n",
    "        pos = self.robot.get_current_position()\n",
    "        return pos[0],pos[1]\n",
    "    \n",
    "    def enc_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.enc_Theta\n",
    "    \n",
    "    def time_global_position(self):\n",
    "        return self.time_global_x, self.time_global_y, self.time_Theta\n",
    "    \n",
    "    \n",
    "    ##Esta seção esta relacionada ao calculo da posição levando em consideração os encoders\n",
    "    def current_encoder_left(self):\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_buffer)\n",
    "        return jL\n",
    "    def current_encoder_right(self):\n",
    "        ret, jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_buffer)\n",
    "        return jR\n",
    "        \n",
    "    #Phi speed of rotation of wheels\n",
    "    def Xr(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Xr = (r*Phi_left/2) + (r*Phi_right/2)\n",
    "        return Xr\n",
    "    \n",
    "    def Theta_r(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Tr = r*Phi_right/(2*self.l) - r*Phi_left/(2*self.l) \n",
    "        return Tr\n",
    "        \n",
    "    def speed_model(self,Phi_right,Phi_left):\n",
    "        #Se formos considerar que o eixo das rodas do robo está deslocado do eixo x\n",
    "        #return np.array([self.Xr(Phi_right,Phi_left),self.Theta_r(Phi_right,Phi_left)*self.l2,self.Theta_r(Phi_right,Phi_left)])\n",
    "        return np.array([self.Xr(Phi_right,Phi_left),0,self.Theta_r(Phi_right,Phi_left)])\n",
    "        \n",
    "    def inverse_rotation_matrix(self, ang):\n",
    "        Trot = np.array([[math.cos(ang), -math.sin(ang), 0], [math.sin(ang), math.cos(ang), 0], [0,0,1]])\n",
    "        return Trot\n",
    "    \n",
    "    def locomotion_global(self, ang, Phi_right, Phi_left):\n",
    "        return np.dot(self.inverse_rotation_matrix(ang),self.speed_model(Phi_right,Phi_left))\n",
    "    \n",
    "    def compute_with_encoder(self):\n",
    "        dxR = self.current_encoder_right() - self.jR\n",
    "        dxL = self.current_encoder_left() - self.jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.enc_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.enc_global_x = self.enc_global_x + qsi[0]\n",
    "        self.enc_global_y = self.enc_global_y + qsi[1]\n",
    "        \n",
    "        #Without gyroscope\n",
    "        #self.enc_Theta = self.enc_Theta + qsi[2]\n",
    "        #with gyroscope\n",
    "        self.enc_Theta = self.robot.read_gyroAngle()[2]\n",
    "        \n",
    "        #Atualiza a posição dos encoders\n",
    "        self.jR = self.current_encoder_right()\n",
    "        self.jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "    \n",
    "    def compute_with_time(self, Phi_right, Phi_left):\n",
    "        #Calculo do delta S\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Vr = r*Phi_right\n",
    "        Vl = r*Phi_left\n",
    "        current_timestamp = datetime.timestamp(datetime.now())\n",
    "        Delta_t = current_timestamp - self.previous_timestamp\n",
    "        #atualiza timestamp imediatamente\n",
    "\n",
    "        self.previous_timestamp = current_timestamp\n",
    "        \n",
    "        Delta_s = (Vr + Vl)*Delta_t/2  \n",
    "        Delta_Theta = (Vr - Vl)*Delta_t/(2*self.l)\n",
    "    \n",
    "        self.time_global_x = self.time_global_x + Delta_s*math.cos(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_global_y = self.time_global_y + Delta_s*math.sin(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_Theta = self.time_Theta + Delta_Theta\n",
    "    \n",
    "    def move(self,Phi_right, Phi_left,seconds): #velocidade em rad/s\n",
    "        #Vamos fixar um tempo de 500ms para computar as distâncias\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #self.compute()\n",
    "            self.robot.set_right_velocity(Phi_right)\n",
    "            self.robot.set_left_velocity(Phi_left)\n",
    "            time.sleep(self.compute_interval)\n",
    "            self.compute_with_encoder()\n",
    "            self.compute_with_time(Phi_right, Phi_left)\n",
    "            self.update_paths()\n",
    "        self.robot.stop()\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def ICR_left(self, Phi_left, R, seconds):\n",
    "        Phi_right = Phi_left*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_left Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "    \n",
    "    def ICR_right(self, Phi_right, R, seconds):\n",
    "        Phi_left = Phi_right*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_right Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "        \n",
    "    def plot_paths(self):\n",
    "        enc_path = np.array(self.enc_path)\n",
    "        time_path = np.array(self.time_path)\n",
    "        true_path = np.array(self.true_path)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "        ax.plot(enc_path[:,0], enc_path[:,1], 1, c='b', label='odometry')\n",
    "        #ax[1].scatter(time_path[:,0], time_path[:,1], 5, c='g', marker='o')\n",
    "        ax.plot(true_path[:,0], true_path[:,1], 1, c='r', label='true path')\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta implementação, o grupo se baseou nas técnicas discutidas em sala de aula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuvem de pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a nuvem de pontos, nós coletamos os dados fornecidos pelo laser (conjunto de pontos) que estão baseados no sistema de referência do robô, após aplicamos a transformação destes pontos para o sistema de referência global. Dados os pontos no sistema global nós realizamos a plotagem dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud():\n",
    "    def __init__(self, robot, us_sensors, laser_sensor):\n",
    "        self.grid_map = None\n",
    "        self.robot = robot\n",
    "        self.us_sensors = us_sensors\n",
    "        self.laser_sensor = laser_sensor\n",
    "        self.res = 0.1\n",
    "        \n",
    "        self.ultrassonic_points = []\n",
    "        self.laser_points = []\n",
    "        self.robot_points = []\n",
    "        \n",
    "        self.gridMapPosPoints = []\n",
    "    \n",
    "    def update(self):\n",
    "        #Insere posição atual do robo\n",
    "        robot_x = self.robot.get_current_position()[0]\n",
    "        robot_y = self.robot.get_current_position()[1]\n",
    "        robot_ang = self.robot.get_current_orientation()[2]\n",
    "        \n",
    "        self.robot_points.append([robot_x,robot_y])\n",
    "\n",
    "        #Atualiza a leitura do laser e insere na nuvem de pontos\n",
    "        self.laser_sensor.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.laser_sensor.laser_x, self.laser_sensor.laser_y):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.laser_points.append([x,y])\n",
    "\n",
    "        #Atualiza a leitura do ultrassonico e insere na nuvem de pontos\n",
    "        self.us_sensors.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.us_sensors.data['robot_frame_reading'][:,0], self.us_sensors.data['robot_frame_reading'][:,1]):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.ultrassonic_points.append([x,y])\n",
    "    \n",
    "    def plot_point_cloud(self):\n",
    "        #Convertendo a nuvem de pontos em um array\n",
    "        ultrassonic_point_array = np.array(self.ultrassonic_points)\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        robot_path = np.array(self.robot_points)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        #posição do centro do robo\n",
    "        ax[0].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[0].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[0].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax[0].scatter(ultrassonic_point_array[:,0],ultrassonic_point_array[:,1], 10, c='magenta', marker='.')\n",
    "\n",
    "        #posição do centro do robo\n",
    "        ax[1].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[1].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[1].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor laser\n",
    "        ax[1].scatter(laser_point_array[:,0],laser_point_array[:,1], 10, c='r', marker='.')\n",
    "\n",
    "        plt.show()\n",
    "          \n",
    "    def set_resolution(self, resolution):\n",
    "        self.res = resolution\n",
    "        \n",
    "    def compute_grid_ocupation(self):\n",
    "        xyreso = self.res  # x-y grid resolution\n",
    "        #yawreso = math.radians(3.1)  # yaw angle resolution [rad]\n",
    "        #ang, dist = file_read(\"lidar01.csv\")\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        ox = laser_point_array[:,0]\n",
    "        oy = laser_point_array[:,1]\n",
    "        self.pmap, self.minx, self.maxx, self.miny, self.maxy, self.xyreso, self.centix, self.centiy = lg.generate_ray_casting_grid_map(ox, oy, xyreso, True)\n",
    "        self.gridwidth = np.array(self.pmap).shape[0]\n",
    "        self.gridheight = np.array(self.pmap).shape[1]\n",
    "        self.grid_map = gm.GridMap( self.gridwidth, self.gridheight, self.res,\n",
    "                 self.centix, self.centiy, init_val= self.pmap)\n",
    "        \n",
    "    def get_idx_from_pos(self, x, y):\n",
    "        ix = int(round((x - self.minx) / self.xyreso)) # x coordinate of the the occupied area\n",
    "        iy = int(round((y - self.miny) / self.xyreso)) # y coordinate of the the occupied area\n",
    "        return ix, iy\n",
    "    \n",
    "    def get_pos_from_idx(self, idx, idy):\n",
    "        x = round((idx*self.xyreso) + self.minx, 2)\n",
    "        y = round((idy*self.xyreso) + self.miny, 2)\n",
    "        return x, y\n",
    "            \n",
    "    def plot_grid_ocupation(self):\n",
    "        plt.figure(figsize=(20,8))\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(self.pmap.T, cmap = \"PiYG_r\") \n",
    "        plt.clim(-0.4, 1.4)\n",
    "        plt.gca().set_xticks(np.arange(-.5, self.gridwidth, 1), minor = True)\n",
    "        plt.gca().set_yticks(np.arange(-.5, self.gridheight, 1), minor = True)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(True, which=\"minor\", color=\"w\", linewidth = .6, alpha = 0.5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    def update_grid_map_pos_points(self):\n",
    "        self.gridMapPosPoints = []\n",
    "        indexes = np.where(self.pmap == 1)\n",
    "        for index in range(len(indexes[0])):\n",
    "            idx_x = indexes[0][index]\n",
    "            idx_y = indexes[1][index]\n",
    "            self.gridMapPosPoints.append(self.get_pos_from_idx(idx_x, idx_y))\n",
    "    \n",
    "    def plot_grid_map_pos_points(self):\n",
    "        point_array = np.array(self.gridMapPosPoints)\n",
    "        plt.scatter(point_array[:,0],point_array[:,1], 10, c='r', marker='.')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "point_cloud = PointCloud(robot, us_sensors, laser_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.update()\n",
    "point_cloud.plot_point_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.compute_grid_ocupation()\n",
    "point_cloud.plot_grid_ocupation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.update_grid_map_pos_points()\n",
    "point_cloud.plot_grid_map_pos_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction():\n",
    "    def __init__(self):\n",
    "        self.clusters = []\n",
    "        self.line_features = {}\n",
    "    \n",
    "    def extract(self, data_points):\n",
    "        self.line_features = {}\n",
    "        self.clusters = self.clusterize(data_points)\n",
    "        for i, cluster in enumerate(self.clusters):\n",
    "            _, segments = self.find_segments(cluster, mode=\"ransac\")\n",
    "            self.line_features[i] =  segments\n",
    "        \n",
    "        new_points = []\n",
    "        for d in list(feature_extraction.line_features.values()):\n",
    "            for dd in list(d.values()):\n",
    "                values = [ a.tolist() for a in dd ]\n",
    "                new_points.extend(values)\n",
    "        return new_points\n",
    "            \n",
    "    def plot_line_features(self):\n",
    "        \n",
    "        for c, cluster in enumerate(self.line_features):\n",
    "            print(self.line_features[cluster])\n",
    "            for l, line in enumerate(self.line_features[cluster]):\n",
    "                plt.scatter(self.clusters[c][:,0], self.clusters[c][:,1], color=np.random.rand(3,), marker='.', label='cluster {}'.format(c))\n",
    "                plt.plot(self.line_features[cluster][line][0], self.line_features[cluster][line][1], color='cornflowerblue', linewidth=2, label='line {}'.format(l))\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "        #plt.legend(loc='lower right')\n",
    "        plt.xlabel(\"Input\")\n",
    "        plt.ylabel(\"Response\")\n",
    "        plt.xlim(-5, 5)\n",
    "        plt.ylim(-5, 5)\n",
    "        plt.show()\n",
    "\n",
    "    def clusterize(self, input_array, debug=False):\n",
    "        raw = input_array\n",
    "\n",
    "        clusters = []\n",
    "        # #############################################################################\n",
    "        # Compute DBSCAN\n",
    "        db = DBSCAN(eps=0.3, min_samples=10).fit(raw)\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "        if (debug):\n",
    "            print(\"DBSCAN clusters: \", n_clusters_)\n",
    "\n",
    "        # #############################################################################\n",
    "        # Plot result\n",
    "        # Black removed and is used for noise instead.\n",
    "        unique_labels = set(labels)\n",
    "        colors = [plt.cm.Spectral(each)\n",
    "                  for each in np.linspace(0, 1, len(unique_labels))]\n",
    "        for k, col in zip(unique_labels, colors):\n",
    "            if k == -1:\n",
    "                # Black used for noise.\n",
    "                col = [0, 0, 0, 1]\n",
    "\n",
    "            class_member_mask = (labels == k)\n",
    "\n",
    "            xy = raw[class_member_mask & core_samples_mask]\n",
    "            clusters.append(xy)\n",
    "\n",
    "            if (debug):\n",
    "                plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                         markeredgecolor=tuple(col), markersize=6, label=\"{}\".format(k))\n",
    "\n",
    "        if (debug):\n",
    "            plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "            plt.ylim(-5, 5)\n",
    "            plt.xlim(-5, 5)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        return clusters\n",
    "    \n",
    "    def extract_lines(self, points, mode=\"linear\", debug=False):\n",
    "        X = points[:,0].reshape(-1,1)\n",
    "        Y = points[:,1]\n",
    "        score = 0\n",
    "\n",
    "        if (mode == \"linear\"):\n",
    "            regr = linear_model.LinearRegression()\n",
    "            regr.fit(X, Y)\n",
    "            score = regr.score(X,Y)\n",
    "            line_X = np.linspace(X.min(), X.max(), 2, endpoint=True).reshape(-1, 1)\n",
    "            line_y = regr.predict(line_X)\n",
    "            if (debug):\n",
    "                lw = 2\n",
    "                plt.scatter(X, Y, color='yellowgreen', marker='.', label='Points')\n",
    "                plt.plot(line_X, line_y, color='cornflowerblue', linewidth=lw, label='Linear regressor')\n",
    "                plt.legend(loc='lower right')\n",
    "                plt.xlabel(\"Input\")\n",
    "                plt.ylabel(\"Response\")\n",
    "                plt.show()\n",
    "\n",
    "        elif (mode == \"ransac\"):\n",
    "            # Robustly fit linear model with RANSAC algorithm\n",
    "            ransac = linear_model.RANSACRegressor(residual_threshold=0.1)\n",
    "            ransac.fit(X, Y)\n",
    "            score = ransac.score(X,Y)\n",
    "            inlier_mask = ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "            inliers = X[inlier_mask]\n",
    "            line_X = np.linspace(inliers.min(), inliers.max(), 2, endpoint=True).reshape(-1, 1)\n",
    "            line_y = ransac.predict(line_X)\n",
    "            if (debug):\n",
    "                lw = 2\n",
    "                plt.scatter(X[inlier_mask], Y[inlier_mask], color='yellowgreen', marker='.', label='Inliers')\n",
    "                plt.scatter(X[outlier_mask], Y[outlier_mask], color='gold', marker='.',label='Outliers')\n",
    "                plt.plot(line_X, line_y, color='cornflowerblue', linewidth=lw, label='RANSAC regressor')\n",
    "                plt.legend(loc='lower right')\n",
    "                plt.xlabel(\"Input\")\n",
    "                plt.ylabel(\"Response\")\n",
    "                plt.show()\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Invalid parameters, use linear or ransac\") \n",
    "\n",
    "\n",
    "        return line_X.flatten(), line_y, score\n",
    "\n",
    "    def find_segments(self, points, mode, debug=False):\n",
    "        sub_clusters = []\n",
    "        line_segments = {}\n",
    "        self.segments(sub_clusters, points, mode)\n",
    "\n",
    "        for i, sub in enumerate(sub_clusters):\n",
    "            line_x, line_y, score = self.extract_lines(sub, mode=mode, debug=False)\n",
    "            line_segments[i] = [line_x, line_y]\n",
    "            if (debug):\n",
    "                plt.scatter(sub[:,0], sub[:,1], color=np.random.rand(3,), marker='.', label='points {}'.format(i))\n",
    "                plt.plot(line_x, line_y, color='cornflowerblue', linewidth=2, label='regressor {}'.format(i))\n",
    "\n",
    "        if (debug):\n",
    "            plt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "            #plt.legend(loc='lower right')\n",
    "            plt.xlabel(\"Input\")\n",
    "            plt.ylabel(\"Response\")\n",
    "            plt.xlim(-5, 5)\n",
    "            plt.ylim(-5, 5)\n",
    "            plt.show()\n",
    "    \n",
    "        return sub_clusters, line_segments\n",
    "\n",
    "    def segments(self, sub_clusters, points, mode):\n",
    "        #scores = []\n",
    "        wscores = {}\n",
    "        for i,x in enumerate(points):\n",
    "            if i > 2:\n",
    "                _, _, score = self.extract_lines(points[0:i], mode=mode)\n",
    "                #scores.append(score)\n",
    "                #wscores.append(score*i)\n",
    "                wscores[i] = score*i\n",
    "                #print(i, score, score*i)\n",
    "        for i,x in enumerate(points):\n",
    "            if i > 2:\n",
    "                _, _, score = self.extract_lines(points[-i:], mode=mode)\n",
    "                #scores.append(score)\n",
    "                #wscores.append(score*i)\n",
    "                wscores[-i] = score*i\n",
    "                #print(-i, score, score*i)\n",
    "\n",
    "        #max_score = max(scores) if len(scores) > 0 else 0\n",
    "        #max_score = max(wscores) if len(wscores) > 0 else 0\n",
    "\n",
    "        #print(\"len wscores\", len(wscores)) \n",
    "        if len(wscores) > 0:\n",
    "            max_score = max(wscores.items(), key=operator.itemgetter(1))[1]\n",
    "            #index_of_max = scores.index(max(scores))\n",
    "            index_of_max = max(wscores.items(), key=operator.itemgetter(1))[0]\n",
    "            #print(\"Index of max \", index_of_max , \" wscore max \", max_score)\n",
    "            if (index_of_max > 0):\n",
    "                sub_clusters.append(points[0:index_of_max+1])\n",
    "                self.segments(sub_clusters, np.delete(points,np.s_[:index_of_max+1],0), mode)\n",
    "            else:\n",
    "                sub_clusters.append(points[index_of_max-1:])\n",
    "                self.segments(sub_clusters, np.delete(points,np.s_[index_of_max-1:],0), mode)\n",
    "feature_extraction = FeatureExtraction()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulamento\n",
    "A classe a seguir encapsula todos os modelos criados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.point_cloud = PointCloud(self.robot, self.us_sensors, self.laser_sensors)\n",
    "        self.featureExtraction = FeatureExtraction()\n",
    "        self.featureExtractionPoints = None\n",
    "        \n",
    "        self.point_cloud.update()\n",
    "    \n",
    "        self.compute_interval = 0.5\n",
    "        \n",
    "        self.braitenbergL=[-0.2,-0.4,-0.6,-0.8,-1.0,-1.2,-1.4,-1.6]\n",
    "        self.braitenbergR=[-1.6,-1.4,-1.2,-1.0,-0.8,-0.6,-0.4,-0.2]\n",
    "\n",
    "        self.detect = [0,0,0,0,0,0,0,0]\n",
    "        self.noDetectionDist = 1.0\n",
    "        self.maxDetectionDist = 0.2\n",
    "        \n",
    "    def braitenberg(self, dist, vel):\n",
    "        vLeft = vRight = vel\n",
    "        for i in range(len(dist)):\n",
    "            if(dist[i] < self.noDetectionDist):\n",
    "                self.detect[i] = 1 - ((dist[i]-self.maxDetectionDist)/(self.noDetectionDist-self.maxDetectionDist))\n",
    "            else:\n",
    "                self.detect[i]=0\n",
    "            for i in range(8):\n",
    "                vLeft = vLeft + self.braitenbergL[i]*self.detect[i]\n",
    "                vRight = vRight+ self.braitenbergR[i]*self.detect[i]\n",
    "                \n",
    "        return [vLeft, vRight]\n",
    "    \n",
    "    \n",
    "    def extractFeatures(self):\n",
    "        self.point_cloud.compute_grid_ocupation()\n",
    "        self.point_cloud.update_grid_map_pos_points()\n",
    "        self.featureExtractionPoints = self.featureExtraction.extract(np.array(self.point_cloud.gridMapPosPoints))\n",
    "        \n",
    "    def startBraintenberg(self,seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            self.point_cloud.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.startBraintenberg(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.kinematicModel.plot_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.point_cloud.plot_point_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.point_cloud.compute_grid_ocupation()\n",
    "mr.point_cloud.plot_grid_ocupation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(self.point_cloud.gridMapPosPoints)\n",
    "#plot_line_features\n",
    "mr.extractFeatures()\n",
    "mr.featureExtraction.plot_line_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "<br>\n",
    "Para o projeto ultilizamos os seguintes sensores:\n",
    "\n",
    "* Encoders\n",
    "* Sensores Ultrassônicos\n",
    "* Laser Hokuyo\n",
    "* Câmera\n",
    "<br><br>\n",
    "<div style=\"text-align: justify\">\n",
    "Os encoders foram utilizados para o processo de odometria, com os dados fornecidos por eles nós estimamos o deslocamento realizado pelo robô no ambiente. Já os sensores ultrassônicos utilizamos para detectar objetos que estivessem mais próximos do robô devido seu curto alcance, porém focamos na utilização do laser para criação da nuvem de pontos por apresentar uma maior precisão e alcance. A utilização da câmera durante o processo foi especificamente para depuração do código, durante a construção do mesmo utilizamos ela para ter uma melhor visão do que estava sendo observado pelo robô.\n",
    "Como mencionado anteriormente os dados obtidos durante a coleta apresentam algumas variações em relação aos dados reais fornecidos pelo simulador V-REP (variações visíveis na odometria), estas variações são mais perceptíveis quando principalmente o robô realiza mudanças de direção, acreditamos que isto deve ocorrer pelo fato da imprecisão dos sensores (neste caso o encoder), o que gera um erro durante os cálculos de estimação de posição, tendo assim um acúmulo de erros durante todo o processo. Uma alternativa para a correção deste erro é a de utilização dos dados do laser como alternativa para minimização destes erros, onde poderíamos pegar pontos de referência na nuvem de pontos para calcularmos os ângulos de rotação e o deslocamento, porém o aperfeiçoamento deste modelo deve ser realizado somente na próxima etapa do trabalho.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
