{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalho 2 - Robótica Movel - MO651\n",
    "#### __Professor(a):__ _Esther Luna Columbini_ <br>\n",
    "__Alunos:__ <br>\n",
    "_Tito Barbosa Rezende_              __RA:__ 025327<br>\n",
    "_João Paulo Franco Assumpção_                        __RA:__ 229322<br>\n",
    "_Elcio Pereira de Souza Junior_     __RA:__ 262952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisitos\n",
    "\n",
    "Instalação das bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.insert(0, '../src')\n",
    "from IPython.display import clear_output\n",
    "from robot import Robot\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import vrep\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Classes e funções do trabalho 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sensor Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser_sensor:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "\n",
    "    def update_robot_frame_reading(self):\n",
    "        laser_flatten_readings = np.array(self.robot.read_laser())\n",
    "        laser_readings = laser_flatten_readings.reshape((len(laser_flatten_readings)//3, 3))\n",
    "        self.laser_x = laser_readings[:,0]\n",
    "        self.laser_y = laser_readings[:,1]\n",
    "\n",
    "def plot_laser_robot_frame():\n",
    "    fig, ax = plt.subplots()\n",
    "    #posição dos feixes laser\n",
    "    ax.scatter(laser_sensor.laser_x, laser_sensor.laser_y, 3, c='g', marker='o')\n",
    "    #posição do centro do robo\n",
    "    ax.scatter(0, 0, 40, c='b', marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sensor Ultrassônico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Us_sensor:\n",
    "    def __init__(self,robot):\n",
    "        orientation_angles = np.array([90,50,30,10,-10,-30,-50,-90,-90,-130,-150,-170,170,150,130,90])\n",
    "        orientation_rad = np.radians(orientation_angles)\n",
    "        self.data = {\n",
    "        \"prefix\" : \"Pioneer_p3dx_ultrasonicSensor\",\n",
    "        \"ids\" : np.arange(1,17,1), \"handles\" : np.zeros(16, dtype=int), \n",
    "        \"positions\" :  np.zeros((16,3),dtype=float),\n",
    "        \"angles_deg\": orientation_angles,\n",
    "        \"angles_rad\": orientation_rad,\n",
    "        \"raw_reading\": np.zeros(16),\n",
    "        \"robot_frame_reading\": np.zeros((16,2),dtype=float)\n",
    "        }\n",
    "        self.robot = robot\n",
    "        \n",
    "        for i,sensor_i in enumerate(self.data['ids']):\n",
    "            ret,handle = vrep.simxGetObjectHandle(self.robot.clientID, self.data['prefix'] + str(sensor_i), vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['handles'][i] = handle\n",
    "            ret, pos = vrep.simxGetObjectPosition(self.robot.clientID, handle, self.robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['positions'][i,:] = pos\n",
    "        \n",
    "    def get_left_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array(self.data[\"raw_reading\"][0]))\n",
    "    \n",
    "    def get_front_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][3:5]]))        \n",
    "    \n",
    "    def get_right_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][7:9]]))\n",
    "    \n",
    "    def update_raw_reading(self):\n",
    "        self.data[\"raw_reading\"] = np.array(self.robot.read_ultrassonic_sensors())\n",
    "    \n",
    "    def update_robot_frame_reading(self):\n",
    "        self.update_raw_reading()\n",
    "        for i, proximity in enumerate(us_sensors.data[\"raw_reading\"]):\n",
    "            if proximity == 5 or proximity < 0.1:\n",
    "                self.data[\"robot_frame_reading\"][i] = np.zeros(2)\n",
    "            else:\n",
    "                self.data[\"robot_frame_reading\"][i] = self.proximity_robot_frame(i+1,proximity).flatten()\n",
    "                \n",
    "    #Calcula o ponto no frame do robo, referente a leitura de cada sensor de proximidade\n",
    "    def proximity_robot_frame(self,sensorId, proximity):\n",
    "        index = sensorId -1\n",
    "        angulars = self.data[\"angles_rad\"][index]\n",
    "        #Matriz de rotação\n",
    "        rot_matrix = np.array([[math.cos(angulars),-math.sin(angulars)],[math.sin(angulars),math.cos(angulars)]])\n",
    "        #Rotacionando a leitura\n",
    "        distXY = np.dot(rot_matrix , np.array([[proximity],[0]]))\n",
    "        #Matriz de translação\n",
    "        posicao_sensor_x = self.data[\"positions\"][index][0]\n",
    "        posicao_sensor_y = self.data[\"positions\"][index][1]\n",
    "        transXY=np.array([[distXY[0][0]+posicao_sensor_x],[distXY[1][0]+posicao_sensor_y]])\n",
    "        return transXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos uma função _toGlobal_ (para termos um melhor reuso de código), basicamente a função transforma um ponto qualquer _(x,y)_ que esteja na referência do robô e o leva para a referência global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,robot_x],[0,1,robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),-math.sin(robot_ang),0],[math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_trans,T_rot)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    return res[0],res[1]\n",
    "def fromGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,-robot_x],[0,1,-robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),math.sin(robot_ang),0],[-math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_rot,T_trans)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    ang = np.arctan2(res[1],res[0])\n",
    "    return res[0],res[1], ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Modelo Cinemático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinematic_model:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "        #Handles dos motores\n",
    "        ret1, self.motorLeft = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret2, self.motorRight = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        #Calcula distancia de eixo\n",
    "        res, left_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, lpos = vrep.simxGetObjectPosition(robot.clientID, left_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        res, right_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, rpos = vrep.simxGetObjectPosition(robot.clientID, right_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        # eixo\n",
    "        self.l = (abs(lpos[1]) + abs(rpos[1]))/2\n",
    "        #Ao ser criado, coleta a referencia de zero do robo\n",
    "        pos = self.robot.get_current_position()\n",
    "        self.initial_pos_x = pos[0]\n",
    "        self.initial_pos_y = pos[1]\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        self.initial_orientation = orientation[2]\n",
    "        #Alem de mantermos a pose inicial, manteremos a pose atualizada do robo\n",
    "        self.enc_global_x = self.initial_pos_x\n",
    "        self.enc_global_y = self.initial_pos_y\n",
    "        self.enc_Theta = self.initial_orientation\n",
    "        self.time_global_x = self.initial_pos_x\n",
    "        self.time_global_y = self.initial_pos_y\n",
    "        self.time_Theta = self.initial_orientation\n",
    "    \n",
    "        #Lista de pontos para o caminho do robo\n",
    "        self.enc_path = []\n",
    "        self.time_path = []\n",
    "        self.true_path = []\n",
    "        self.update_paths()    \n",
    "        #inicializando a posição dos encoders\n",
    "        self.jL = self.current_encoder_left()\n",
    "        self.jR = self.current_encoder_right()\n",
    "        #intervalo entre cada calculo\n",
    "        self.compute_interval = 0.1\n",
    "        self.previous_timestamp = 0\n",
    "        \n",
    "    def update_paths(self):\n",
    "        self.enc_path.append([self.enc_global_x, self.enc_global_y, self.enc_Theta])\n",
    "        self.time_path.append([self.time_global_x, self.time_global_y, self.time_Theta])\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        true_theta = orientation[2]\n",
    "        current_position = self.true_global_position()\n",
    "        self.true_path.append([current_position[0], current_position[1], true_theta])\n",
    "    \n",
    "    def true_global_position(self):\n",
    "        pos = self.robot.get_current_position()\n",
    "        return pos[0],pos[1]\n",
    "    \n",
    "    def enc_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.enc_Theta\n",
    "    \n",
    "    def time_global_position(self):\n",
    "        return self.time_global_x, self.time_global_y, self.time_Theta\n",
    "    \n",
    "    ##Esta seção esta relacionada ao calculo da posição levando em consideração os encoders\n",
    "    def current_encoder_left(self):\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_oneshot_wait)\n",
    "        return jL\n",
    "    \n",
    "    def current_encoder_right(self):\n",
    "        ret, jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_oneshot_wait)\n",
    "        return jR    \n",
    "    \n",
    "    #Phi speed of rotation of wheels\n",
    "    def Xr(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Xr = (r*Phi_left/2) + (r*Phi_right/2)\n",
    "        return Xr\n",
    "    \n",
    "    def Theta_r(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Tr = r*Phi_right/(2*self.l) - r*Phi_left/(2*self.l) \n",
    "        return Tr\n",
    "        \n",
    "    def speed_model(self,Phi_right,Phi_left):\n",
    "        #Se formos considerar que o eixo das rodas do robo está deslocado do eixo x\n",
    "        #return np.array([self.Xr(Phi_right,Phi_left),self.Theta_r(Phi_right,Phi_left)*self.l2,self.Theta_r(Phi_right,Phi_left)])\n",
    "        return np.array([self.Xr(Phi_right,Phi_left),0,self.Theta_r(Phi_right,Phi_left)])\n",
    "        \n",
    "    def inverse_rotation_matrix(self, ang):\n",
    "        Trot = np.array([[math.cos(ang), -math.sin(ang), 0], [math.sin(ang), math.cos(ang), 0], [0,0,1]])\n",
    "        return Trot\n",
    "    \n",
    "    def locomotion_global(self, ang, Phi_right, Phi_left):\n",
    "        return np.dot(self.inverse_rotation_matrix(ang),self.speed_model(Phi_right,Phi_left))\n",
    "    \n",
    "    def compute_with_encoder(self):\n",
    "        dxR = self.current_encoder_right() - self.jR\n",
    "        dxL = self.current_encoder_left() - self.jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.enc_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.enc_global_x = self.enc_global_x + qsi[0]\n",
    "        self.enc_global_y = self.enc_global_y + qsi[1]\n",
    "        self.enc_Theta = self.enc_Theta + qsi[2]\n",
    "        #Atualiza a posição dos encoders\n",
    "        self.jR = self.current_encoder_right()\n",
    "        self.jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "    \n",
    "    def compute_with_time(self, Phi_right, Phi_left):\n",
    "        #Calculo do delta S\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Vr = r*Phi_right\n",
    "        Vl = r*Phi_left\n",
    "        current_timestamp = datetime.timestamp(datetime.now())\n",
    "        Delta_t = current_timestamp - self.previous_timestamp\n",
    "        #atualiza timestamp imediatamente\n",
    "\n",
    "        self.previous_timestamp = current_timestamp\n",
    "        \n",
    "        Delta_s = (Vr + Vl)*Delta_t/2  \n",
    "        Delta_Theta = (Vr - Vl)*Delta_t/(2*self.l)\n",
    "    \n",
    "        self.time_global_x = self.time_global_x + Delta_s*math.cos(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_global_y = self.time_global_y + Delta_s*math.sin(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_Theta = self.time_Theta + Delta_Theta\n",
    "    \n",
    "    def move(self,Phi_right, Phi_left,seconds): #velocidade em rad/s\n",
    "        #Vamos fixar um tempo de 500ms para computar as distâncias\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #self.compute()\n",
    "            self.robot.set_right_velocity(Phi_right)\n",
    "            self.robot.set_left_velocity(Phi_left)\n",
    "            time.sleep(self.compute_interval)\n",
    "            self.compute_with_encoder()\n",
    "            self.compute_with_time(Phi_right, Phi_left)\n",
    "            self.update_paths()\n",
    "        self.robot.stop()\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def turnGlobal(self, input_ang):\n",
    "        orientation = self.robot.get_current_orientation()[2]\n",
    "        ang = input_ang\n",
    "        if (orientation < 0):\n",
    "            orientation = orientation + 2*math.pi\n",
    "        if (ang < 0):\n",
    "            ang = ang + 2*math.pi\n",
    "            \n",
    "        print(\"Initial orientation \", orientation)\n",
    "        print(\"Ang \", ang)\n",
    "        vel = 0.2\n",
    "        \n",
    "        if ((ang - orientation) > math.pi) or (0 > (ang - orientation) > -math.pi):\n",
    "            vel = - vel\n",
    "        \n",
    "        self.robot.set_right_velocity(vel)\n",
    "        self.robot.set_left_velocity(-vel)\n",
    "        tolerance = math.pi/90\n",
    "        while ((ang - orientation) > tolerance) or ((ang - orientation) < -tolerance):\n",
    "            time.sleep(0.05)\n",
    "            orientation = self.robot.get_current_orientation()[2]\n",
    "            if (orientation < 0):\n",
    "                orientation = orientation + 2*math.pi\n",
    "            sys.stdout.write(\"\\r\" + \"Diff \" + str((ang - orientation)) + \" orientation \" + str(orientation))\n",
    "            sys.stdout.flush()\n",
    "        self.robot.stop()\n",
    "        print(\"curr orientation \", orientation)        \n",
    "        \n",
    "    def ICR_left(self, Phi_left, R, seconds):\n",
    "        Phi_right = Phi_left*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_left Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "    \n",
    "    def ICR_right(self, Phi_right, R, seconds):\n",
    "        Phi_left = Phi_right*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_right Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "  \n",
    "    def plot_paths(self):\n",
    "        enc_path = np.array(self.enc_path)\n",
    "        time_path = np.array(self.time_path)\n",
    "        true_path = np.array(self.true_path)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "        ax[0].scatter(enc_path[:,0], enc_path[:,1], 5, c='b', marker='o')\n",
    "        #ax[1].scatter(time_path[:,0], time_path[:,1], 5, c='g', marker='o')\n",
    "        ax[1].scatter(true_path[:,0], true_path[:,1], 5, c='r', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Nuvem de pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a nuvem de pontos, nós coletamos os dados fornecidos pelo laser (conjunto de pontos) que estão baseados no sistema de referência do robô, após aplicamos a transformação destes pontos para o sistema de referência global. Dados os pontos no sistema global nós realizamos a plotagem dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud():\n",
    "    def __init__(self, robot, us_sensors, laser_sensor):\n",
    "        self.robot = robot\n",
    "        self.us_sensors = us_sensors\n",
    "        self.laser_sensor = laser_sensor\n",
    "        \n",
    "        self.ultrassonic_points = []\n",
    "        self.laser_points = []\n",
    "        self.robot_points = []\n",
    "    \n",
    "    def update(self):\n",
    "        #Insere posição atual do robo\n",
    "        robot_x = self.robot.get_current_position()[0]\n",
    "        robot_y = self.robot.get_current_position()[1]\n",
    "        robot_ang = self.robot.get_current_orientation()[2]\n",
    "        \n",
    "        self.robot_points.append([robot_x,robot_y])\n",
    "\n",
    "        #Atualiza a leitura do laser e insere na nuvem de pontos\n",
    "        self.laser_sensor.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.laser_sensor.laser_x, self.laser_sensor.laser_y):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.laser_points.append([x,y])\n",
    "\n",
    "        #Atualiza a leitura do ultrassonico e insere na nuvem de pontos\n",
    "        self.us_sensors.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.us_sensors.data['robot_frame_reading'][:,0], self.us_sensors.data['robot_frame_reading'][:,1]):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.ultrassonic_points.append([x,y])\n",
    "    \n",
    "    def plot_point_cloud(self):\n",
    "        #Convertendo a nuvem de pontos em um array\n",
    "        ultrassonic_point_array = np.array(self.ultrassonic_points)\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        robot_path = np.array(self.robot_points)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        #posição do centro do robo\n",
    "        ax[0].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[0].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax[0].scatter(ultrassonic_point_array[:,0],ultrassonic_point_array[:,1], 10, c='magenta', marker='.')\n",
    "\n",
    "        #posição do centro do robo\n",
    "        ax[1].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[1].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor laser\n",
    "        ax[1].scatter(laser_point_array[:,0],laser_point_array[:,1], 10, c='r', marker='.')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Code of Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general objective of this work is to build, on the V-REP robotic simulator, a set of behaviors to control a Pioneer P3-DX robot.\n",
    "3 Behaviours were developed:<br>\n",
    "    <blockquote>2.1 AvoidObstacle<br>\n",
    "    2.2 WallFollow<br>\n",
    "    2.3 GoToGoal</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - AvoidObstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behaviour was implemented using Fuzzy logic. In other to correctlly demonstrate the behaviour, a simple wandering algorithim is simulated bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start robot and test the 8 frontal sonar sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n",
      "[5.0, 5.0, 5.0, 0.9731929898262024, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "robot = Robot()\n",
    "distances = robot.read_ultrassonic_sensors()\n",
    "frontal = distances[:8]\n",
    "print(frontal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bellow Fuzzyfication function was implemented, receiving as its input the reading of the sonar sensors. The eight frontal sonar sensors was classified into 3 groups: left sensors (__x_l:__ 1 to 3 sensors); forward (__x_f:__ 3 to 6 sensors) and; right (__x_r:__ 6 to 8 sensors). For fuzzification we adopted the minimal value each one.\n",
    "\n",
    "We choose 0.1m as __near__ and values between 0.1 and 0.4m as __almost near__. Far value was considered irrelevant in results.\n",
    "\n",
    "The function print a graphic result if you set the __\\_print__ value to __1__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward sensors fuzzyfication: -1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sensor_fuzzyfication(frontal_sensors,_print=0, _near=0.1, _almost_near=0.4) :\n",
    "    x_v = np.arange(-0.1, 5.1, 0.01)\n",
    "    t_close = [-0.1, -0.1, _near, _almost_near]\n",
    "    mfx_close = fuzz.trapmf(x_v, t_close)\n",
    "    #t_far = [0.3, .55, 5, 5]                /// Results are irrelevant\n",
    "    #mfx_far = fuzz.trapmf(x_v, t_far)       /// Results are irrelevant\n",
    "    x_l = np.array([round(min(frontal_sensors[:2]))])    # Left sensors\n",
    "    x_f = np.array([min(frontal_sensors[3:5])])          # Forward Sensors\n",
    "    x_r = np.array([round(min(frontal_sensors[6:8]),1)]) # Right sensors\n",
    "    y_l = np.array([-1]) # Null value\n",
    "    y_f = np.array([-1]) # Null value\n",
    "    y_r = np.array([-1]) # Null value\n",
    "    if(x_l[0] < _almost_near) :\n",
    "        y_l = fuzz.trapmf(x_l, t_close) # Return fuzzy value for left sensors\n",
    "    if(x_f[0] < _almost_near) :\n",
    "        y_f = fuzz.trapmf(x_f, t_close) # Return fuzzy value for forward sensors\n",
    "    if(x_r[0] < _almost_near) :\n",
    "        y_r = fuzz.trapmf(x_r, t_close) # Return fuzzy value for right sensors\n",
    "    \n",
    "    # Just for print mode\n",
    "    if (_print > 0) : \n",
    "        plt.plot(x_v, mfx_close,label=\"Near\")\n",
    "        colors = ['tab:black','tab:cyan','tab:purple','tab:green','tab:red','tab:brown','tab:olive','tab:gray','tab:pink']\n",
    "        if(x_l[0] < 1) : plt.vlines(x_l, 0, y_l, label=\"min_left\",color=colors[1]); print(\"Left sensors fuzzyfication: \"+str(y_l[0]))\n",
    "        if(x_f[0] < 1) : plt.vlines(x_f, 0, y_f, label=\"min_forward\",color=colors[2]); print(\"Forward sensors fuzzyfication: \"+str(y_f[0]))\n",
    "        if(x_r[0] < 1) : plt.vlines(x_r[0], 0, y_r, label=\"min_right\",color=colors[3]); print(\"Right sensors fuzzyfication: \"+str(y_r[0]))\n",
    "        plt.ylabel('Fuzzy value')\n",
    "        plt.xlabel('Proximity (m)')\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "        plt.legend(loc=1)\n",
    "        plt.draw()\n",
    "        plt.pause(0.05)\n",
    "    \n",
    "    # Return useful value: used X range; Y result values and; near trapezoidal.\n",
    "    return x_v, y_l, y_f, y_r, t_close\n",
    "\n",
    "fuzzy = sensor_fuzzyfication(frontal,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object avoidance will be given by the defuzzyfication function bellow, acting in oposition to the proximitiy sensor. The function starts an initial verification if the frontal sensors minimal value is grater than 0.4m (our almost near value). In this case it returns the angular velocity equal 2 to both wheels. Else, it goes to defuzzification angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avoidByDefuzzyfication(frontal_sensors,fuzzy_results, _print=0) :\n",
    "    if (min(frontal_sensors) > fuzzy_results[4][3]) : # in case all frontal sensor is grater than almost near\n",
    "        velL = 2\n",
    "        velR = 2\n",
    "        return velL, velR           # Stop function and return equal values. \n",
    "                                    # This condition avoid a defuzzy error obtaining a null crisp value\n",
    "    y_v = np.arange(-95, 95, 1)\n",
    "    x_v = fuzzy_results[0]\n",
    "\n",
    "    mfy_left = fuzz.trimf(y_v, [-95, -95,-10])       # Values to get  a left collision probabillity\n",
    "    mfy_forward = fuzz.trapmf(y_v, [-60,-30, 30,60]) # Values to get  a forward collision probabillity\n",
    "    mfy_right = fuzz.trimf(y_v, [10,95,95])          # Values to get  a right collision probabillity\n",
    "\n",
    "    proximityL = ctrl.Antecedent(x_v, 'proximityL')\n",
    "    proximityR = ctrl.Antecedent(x_v, 'proximityR')\n",
    "    proximityF = ctrl.Antecedent(x_v, 'proximityF')\n",
    "    prob = ctrl.Consequent(y_v, 'Collision')         # Collision probabillity\n",
    "\n",
    "    proximity = fuzz.trapmf(x_v,[-0.1, -0.1, fuzzy_results[4][2], fuzzy_results[4][3]])\n",
    "    proximityL['near'] = proximity\n",
    "    proximityR['near'] = proximity\n",
    "    proximityF['near'] = proximity\n",
    "    prob['Left'] = mfy_left\n",
    "    prob['Forward'] = mfy_forward\n",
    "    prob['Right'] = mfy_right\n",
    "\n",
    "\n",
    "    # This method define 3 rules to get our fuzzy set\n",
    "    rule1 = ctrl.Rule(proximityL['near'] , prob['Left'])\n",
    "    rule2 = ctrl.Rule(proximityF['near'] , prob['Forward'])\n",
    "    rule3 = ctrl.Rule(proximityR['near'], prob['Right'])\n",
    "\n",
    "    vel_ctrl = ctrl.ControlSystem([rule1, rule2, rule3]) # Defuzzy rules for collision possibility\n",
    "    vel = ctrl.ControlSystemSimulation(vel_ctrl)\n",
    "\n",
    "    vel.input['proximityL'] = min(frontal_sensors[:3])\n",
    "    vel.input['proximityR'] = min(frontal_sensors[5:8])\n",
    "    vel.input['proximityF'] = min(frontal_sensors[2:6])\n",
    "\n",
    "    if (_print > 0) :\n",
    "        # Print minimal sensor distances\n",
    "        print(\"Distance Left: \"+str(min(frontal[:3])))\n",
    "        print(\"Distance Forward: \"+str(min(frontal[2:6])))\n",
    "        print(\"Distance Right: \"+str(min(frontal[5:8])))\n",
    "\n",
    "    vel_output = 1\n",
    "\n",
    "    if (min(frontal_sensors) <= 1):\n",
    "        vel.compute()\n",
    "        # Using Mamdani's method we output a fuzzy set \n",
    "        # and obtain a crisp value from centroid\n",
    "        \n",
    "        vel_output = round(vel.output['Collision'])   # Collision angle probabillity crisp value\n",
    "        Collision = \"Collision: \"+str(vel_output)+\"°\"\n",
    "    else: Collision = \"No collision\"\n",
    "    if (_print > 0) :\n",
    "        print(Collision)\n",
    "        prob.view(sim=vel)\n",
    "    \n",
    "    x_w = np.arange(-100,100,0.1)\n",
    "    wlv = [-100, -100,0,50]    # Fuzzify crisp value to obtain left wheel angular velocity\n",
    "    wrv = [0,10,100,100]       # Fuzzify crisp value to obtain right wheel angular velocity\n",
    "    # We use diferent trapezoidal graphics for the wheels to avoid equal speed in frontal collision possibility\n",
    "    \n",
    "    x = np.array([vel_output])\n",
    "    y_l=fuzz.trapmf(x, wlv)    # Fuzzy value for left wheel\n",
    "    y_r=fuzz.trapmf(x, wrv)    # Fuzzy value for right wheel\n",
    "    if (_print > 0) :\n",
    "        #Print graphics\n",
    "        WheelL = fuzz.trapmf(x_w, wlv)\n",
    "        WheelR = fuzz.trapmf(x_w, wrv)\n",
    "        plt.plot(x_w, WheelL,label=\"Wheel Left\")\n",
    "        plt.plot(x_w, WheelR,label=\"Wheel Right\")\n",
    "        plt.vlines(x, 0, y_l, label=\"Collision\")\n",
    "        plt.vlines(x, 0, y_r)\n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "        plt.pause(0.05)\n",
    "        print(\"Wheel left angular velocity: \"+str((y_l[0]-0.5)/0.25))\n",
    "        print(\"Wheel right angular velocity: \"+str((y_r[0]-0.5)/0.25))\n",
    "    \n",
    "    velL = (y_l[0]-0.5)/0.25    #Convert Fuzzy value into angular speed for left wheel\n",
    "    velR = (y_r[0]-0.5)/0.25    #Convert Fuzzy value into angular speed for right wheel\n",
    "\n",
    "    return velL, velR\n",
    "avoidByDefuzzyfication(frontal,fuzzy,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mobile robot class, implementing the fuzzy controller will be given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobotAvoid():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.compute_interval = 0.2\n",
    "        \n",
    "    def control(self, frontal):\n",
    "        fuzzy = sensor_fuzzyfication(frontal)\n",
    "        avoid = avoidByDefuzzyfication(frontal,fuzzy)    # Defuzzyfication\n",
    "        return avoid[0], avoid[1]                        # Return angular speed from the sensors\n",
    "\n",
    "    def startWander(self, seconds):\n",
    "        \n",
    "        for step in range(int(seconds/self.compute_interval)): # Repeat avoidance each 0.2s (self.compute_interval)\n",
    "            Phi_l, Phi_r = self.control(self.robot.read_ultrassonic_sensors()[:8]) # Get angular speed from avoidance function\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)           # Apply angular speed to kinematic model\n",
    "            \n",
    "mr = MobileRobotAvoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow, test startWander function for 50s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.startWander(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion:__ We tested __startWander__ function for 60 minutes and the robot didn't collide or stop, avoiding each obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Wall Follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behaviour was implemented using a PID controller. In other to demonstrate the behaviour, two classes were created.One of the PID controller itselft, and the other a Robot Class, which uses the previous work of Project 1 kinematic model and sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 PID Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PID gains were obtained experimentally. Both Integral and Derivative did not performed well on hour case, specially during the countour of the couch. For P gains lower than 1, the robot is too slow to correct its trajectory and ocasionally the distance of the wall becomes greather than 1 meter and the robot stops following the wall. If the P gain is too high, the controller correction is too great and the robot overshots, turning around its own axis trying to go back to the wall, which causes the left sensor to loose the wall reading.\n",
    "We can perceive here that with the controller alone is very dificult to guide the robot. Thus, there is a need for a behaviour coordination strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PID():\n",
    "    def __init__(self, P=1, I=0.0, D=0, Derivator=0, Integrator=0, Integrator_max=500, Integrator_min=-500):\n",
    "        self.Kp=P\n",
    "        self.Ki=I\n",
    "        self.Kd=D\n",
    "        self.Derivator=Derivator\n",
    "        self.Integrator=Integrator\n",
    "        self.Integrator_max=Integrator_max\n",
    "        self.Integrator_min=Integrator_min\n",
    "        self.set_point=0.0\n",
    "        self.error=0.0\n",
    "        self.IntegralWindow = collections.deque(maxlen=10)\n",
    "        \n",
    "    def update(self,current_value):\n",
    "        self.error = self.set_point - current_value\n",
    "        self.P_value = self.Kp * self.error\n",
    "        self.D_value = self.Kd * ( self.error - self.Derivator)\n",
    "        self.Derivator = self.error\n",
    "        self.IntegralWindow.append(self.error)\n",
    "        self.Integrator = sum(self.IntegralWindow)\n",
    "\n",
    "        if self.Integrator > self.Integrator_max:\n",
    "            self.Integrator = self.Integrator_max\n",
    "        elif self.Integrator < self.Integrator_min:\n",
    "            self.Integrator = self.Integrator_min\n",
    "\n",
    "        self.I_value = self.Integrator * self.Ki\n",
    "\n",
    "        PID = self.P_value + self.I_value + self.D_value\n",
    "        #print(\"PID cv \",current_value ,\" sp \", self.set_point ,\" error \", self.error ,\" pid \", PID)\n",
    "        sys.stdout.write(\"\\r\" + \"PID cv \" + str(current_value) + \" sp \" + str(self.set_point) + \" error \" + str(self.error) + \" pid \" + str(PID))\n",
    "        sys.stdout.flush()\n",
    "        return PID\n",
    "\n",
    "    def setPoint(self,set_point):\n",
    "        self.set_point = set_point\n",
    "        self.Integrator=0\n",
    "        self.Derivator=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.pidL = PID()\n",
    "        self.pidL.setPoint(0.5)\n",
    "        self.compute_interval = 0.5\n",
    "        self.follow_wall_side = \"LEFT\"\n",
    "        \n",
    "        self.curr_state = None\n",
    "        self.prev_state = None\n",
    "        \n",
    "    def checkCurrentState(self):\n",
    "        previous_state = self.curr_state\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        #Initial state: Move Foward\n",
    "        if (previous_state == None and self.prev_state == None):\n",
    "            self.curr_state = 'MoveFoward'\n",
    "    \n",
    "        #MF->TR\n",
    "        if (previous_state == 'MoveFoward' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #TR->WF\n",
    "        if (previous_state == 'TurnRight' and left <= 1):\n",
    "            self.curr_state = 'WallFollow'\n",
    "            \n",
    "        #WF->TR\n",
    "        if (previous_state == 'WallFollow' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #WF->MoveFoward\n",
    "        if (previous_state == 'WallFollow' and front == 5 and left == 5):\n",
    "            self.curr_state = 'MoveFoward'\n",
    "          \n",
    "        #update prev\n",
    "        self.prev_state = previous_state\n",
    "    \n",
    "    def control(self, left_distance, right_distance, front_distance ):\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        vel = 0\n",
    "        turn = 0\n",
    "        self.checkCurrentState()\n",
    "        \n",
    "        #State Machine\n",
    "        ##Move foward\n",
    "        if (self.curr_state == 'MoveFoward'):\n",
    "            turn = 0\n",
    "            vel = 3\n",
    "        ##Turn Right\n",
    "        elif (self.curr_state == 'TurnRight'):\n",
    "            turn = 1\n",
    "            vel = 0\n",
    "        #Wall Follow\n",
    "        elif (self.curr_state == 'WallFollow'):\n",
    "            turn = self.pidL.update(left_distance)\n",
    "            vel = 1\n",
    "        #Turn Back\n",
    "#         elif (self.curr_state == 'TurnBack'):\n",
    "#             turn = -1\n",
    "#             vel = 0\n",
    "        self.prev_state = self.curr_state\n",
    "        return vel + turn, vel - turn\n",
    "\n",
    "    def start(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            Phi_l, Phi_r = self.control(self.us_sensors.get_left_distance(),self.us_sensors.get_right_distance(), self.us_sensors.get_front_distance())\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            #self.point_cloud.update()\n",
    "            #self.point_cloud.plot_point_cloud()\n",
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID cv 0.38602718710899353 sp 0.5 error 0.11397281289100647 pid 0.11397281289100647776"
     ]
    }
   ],
   "source": [
    "mr.start(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Go To Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of moving forward on robot current direction, we could implement a behaviour to Go to a specific point on the global reference.\n",
    "The implementation is given by the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_diretion(robot, us_sensors, go_point_x, go_point_y, _print=0):\n",
    "    \n",
    "    # global position of robot\n",
    "    robot_x = robot.get_current_position()[0]\n",
    "    robot_y = robot.get_current_position()[1]\n",
    "    robot_ang = robot.get_current_orientation()[2]\n",
    "    \n",
    "    # relative vector to goal\n",
    "    vec_x_go = go_point_x - robot_x\n",
    "    vec_y_go = go_point_y - robot_y\n",
    "    \n",
    "    # angle between position and goal vector\n",
    "    #vector origin\n",
    "    \n",
    "    ang = math.acos( vec_x_go / ( math.sqrt(math.pow(vec_x_go,2)+math.pow(vec_y_go,2)) ) )\n",
    "\n",
    "    if (_print==1):\n",
    "        print(\"ang:\")\n",
    "        print(ang)\n",
    "        print(\"ang robot:\")\n",
    "        print(robot_ang)\n",
    "    \n",
    "    if robot_y > 0:\n",
    "        ang = -ang\n",
    "\n",
    "    if (_print==0):\n",
    "        print(\"After:\")\n",
    "        print(robot.get_current_orientation()[2])\n",
    "\n",
    "        # plot\n",
    "        plt.plot([0,0],[-7.5,7.5], color='g')\n",
    "        plt.plot([-7.5,7.5], [0,0], color='r')\n",
    "        origin = [robot_x, robot_y]\n",
    "\n",
    "        #plt.quiver(*origin, data1, data2, color=['b'], scale=30)\n",
    "        #plt.quiver(*origin, vec_x_sum, vec_y_sum, color=['r'])\n",
    "        plt.scatter([3.5],[5], color='r', marker = '*', s = 100)\n",
    "        plt.quiver(*origin, vec_x_go, vec_y_go, color=['b'])\n",
    "\n",
    "        plt.axis([-7.5,7.5,-7.5,7.5])\n",
    "        plt.show()\n",
    "        \n",
    "    return ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.compute_interval = 0.5\n",
    "        self.follow_wall_side = \"LEFT\"\n",
    "        \n",
    "        self.curr_state = None\n",
    "        self.prev_state = None\n",
    "        \n",
    "        self.go_x = 0\n",
    "        self.go_y = 0\n",
    "    \n",
    "    def direction(self):\n",
    "        return give_diretion(self.robot, self.us_sensors, self.go_x, self.go_y, 1)\n",
    "        \n",
    "    def setGoal(self, x, y):\n",
    "        self.go_x = x\n",
    "        self.go_y = y\n",
    "        \n",
    "    def checkFinal(self):\n",
    "        curr_x, curr_y = self.kinematicModel.true_global_position()\n",
    "        return (abs(curr_x - self.go_x) < 0.1) and (abs(curr_y - self.go_y) < 0.1)\n",
    "    \n",
    "    def checkCorrectDirection(self):\n",
    "        go_direction = self.direction()\n",
    "        robot_direction = self.robot.get_current_orientation()[2]\n",
    "        print(\"Go direction \", go_direction, \"Robot direction \", robot_direction)\n",
    "        return (abs(go_direction - robot_direction) < 0.1)\n",
    "        \n",
    "    def checkCurrentState(self):\n",
    "        previous_state = self.curr_state\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        \n",
    "        \n",
    "        #Initial state: Turn to Direction\n",
    "        if (previous_state == None and self.prev_state == None):\n",
    "            self.curr_state = 'Turn'\n",
    "    \n",
    "        #Turn->MoveForward\n",
    "        if (previous_state == 'Turn' and self.checkCorrectDirection()):\n",
    "            self.curr_state = 'MoveForward'\n",
    "            \n",
    "        #MoveForward->Turn\n",
    "        if (previous_state == 'MoveForward' and not self.checkCorrectDirection()):\n",
    "            self.curr_state = 'Turn'\n",
    "            \n",
    "        #MoveForward->Final\n",
    "        if (previous_state == 'MoveForward' and self.checkFinal()):\n",
    "            self.curr_state = 'Final'\n",
    "          \n",
    "        #update prev\n",
    "        self.prev_state = previous_state\n",
    "        \n",
    "        print(self.curr_state)\n",
    "    \n",
    "    def control(self, left_distance, right_distance, front_distance ):\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        vel = 0\n",
    "        turn = 0\n",
    "        self.checkCurrentState()\n",
    "        \n",
    "        #State Machine\n",
    "        ##Turn\n",
    "        if (self.curr_state == 'Turn'):\n",
    "            turn = 0\n",
    "            vel = 0\n",
    "            self.kinematicModel.turnGlobal(self.direction())\n",
    "        ##MoveForward\n",
    "        elif (self.curr_state == 'MoveForward'):\n",
    "            turn = 0\n",
    "            vel = 2\n",
    "        #Final\n",
    "        elif (self.curr_state == 'Final'):\n",
    "            turn = 0\n",
    "            vel = 0\n",
    "            self.robot.stop()\n",
    "        #Turn Back\n",
    "#         elif (self.curr_state == 'TurnBack'):\n",
    "#             turn = -1\n",
    "#             vel = 0\n",
    "        self.prev_state = self.curr_state\n",
    "        return vel + turn, vel - turn\n",
    "\n",
    "    def start(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            Phi_l, Phi_r = self.control(self.us_sensors.get_left_distance(),self.us_sensors.get_right_distance(), self.us_sensors.get_front_distance())\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            #self.point_cloud.update()\n",
    "            #self.point_cloud.plot_point_cloud()\n",
    "            if (self.checkFinal()):\n",
    "                break\n",
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go direction  -0.9578437792662522 Robot direction  2.4706504344940186\n",
      "Final\n"
     ]
    }
   ],
   "source": [
    "mr.start(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Behaviour Coordenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.pidL = PID()\n",
    "        self.pidL.setPoint(0.5)\n",
    "        self.pidR = PID()\n",
    "        self.pidR.setPoint(0.5)\n",
    "        self.compute_interval = 0.5\n",
    "   \n",
    "        self.go_x = 0\n",
    "        self.go_y = 0\n",
    "    \n",
    "    def direction(self):\n",
    "        return give_diretion(self.robot, self.us_sensors, self.go_x, self.go_y, 1)\n",
    "        \n",
    "    def setGoal(self, x, y):\n",
    "        self.go_x = x\n",
    "        self.go_y = y\n",
    "        \n",
    "    def checkFinal(self):\n",
    "        curr_x, curr_y = self.kinematicModel.true_global_position()\n",
    "        return (abs(curr_x - self.go_x) < 0.1) and (abs(curr_y - self.go_y) < 0.1)\n",
    "    \n",
    "    def checkCorrectDirection(self):\n",
    "        go_direction = self.direction()\n",
    "        robot_direction = self.robot.get_current_orientation()[2]\n",
    "        print(\"Go direction \", go_direction, \"Robot direction \", robot_direction)\n",
    "        return (abs(go_direction - robot_direction) < 0.1)\n",
    "    \n",
    "    def fuzzyControl(self):\n",
    "        frontal = self.robot.read_ultrassonic_sensors()[:8]\n",
    "        fuzzy = sensor_fuzzyfication(frontal,0,0.05,0.1) # Call function fuzzy and set near=0.05 and almost_near=0.1\n",
    "        avoid = avoidByDefuzzyfication(frontal,fuzzy)\n",
    "        return avoid[0], avoid[1]\n",
    "    \n",
    "    def wallFollowControl(self):\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        vel = 0\n",
    "        turn = 0\n",
    "        \n",
    "        #Wall Follow\n",
    "        if (left < right):\n",
    "            turn = self.pidL.update(left)\n",
    "            vel = 1\n",
    "        else:\n",
    "            turn = self.pidR.update(right)\n",
    "            vel = 1\n",
    "            \n",
    "        return vel + turn, vel - turn\n",
    "    \n",
    "    def control(self):\n",
    "        vel_l = 0\n",
    "        vel_r = 0\n",
    "    \n",
    "        #1st Priority: Avoid Obstacle\n",
    "        min_frontal = np.min(np.array(self.robot.read_ultrassonic_sensors()[3:6]))\n",
    "        if (min_frontal <= 0.5):\n",
    "            vel_l, vel_r = self.fuzzyControl()\n",
    "            print(\"Avoid Obstacle\")\n",
    "        #2st Priority: Wall Follow\n",
    "        elif ((self.us_sensors.get_left_distance() < 1) or (self.us_sensors.get_right_distance() < 1)):\n",
    "            vel_l, vel_r = self.wallFollowControl()\n",
    "            print(\"Wall Follow\")\n",
    "        #4th Priority: Turn\n",
    "        elif (not self.checkCorrectDirection()):\n",
    "            self.kinematicModel.turnGlobal(self.direction())\n",
    "            print(\"Turn\")\n",
    "        #5th Priority: GoToGo\n",
    "        else:\n",
    "            vel_l = 2\n",
    "            vel_r = 2\n",
    "            print(\"GoToGo\")\n",
    "        return vel_l, vel_r\n",
    "\n",
    "    def start(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            Phi_l, Phi_r = self.control()\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            #self.point_cloud.update()\n",
    "            #self.point_cloud.plot_point_cloud()\n",
    "            if (self.checkFinal()):\n",
    "                self.robot.stop()\n",
    "                break\n",
    "                \n",
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avoid Obstacle\n",
      "PID cv 0.40915459394454956 sp 0.5 error 0.09084540605545044 pid 0.09084540605545044Wall Follow\n",
      "PID cv 0.5570551753044128 sp 0.5 error -0.05705517530441284 pid -0.05705517530441284Wall Follow\n",
      "PID cv 0.7062653303146362 sp 0.5 error -0.20626533031463623 pid -0.20626533031463623Wall Follow\n",
      "Go direction  -0.9358352150171559 Robot direction  1.1013561487197876\n",
      "Initial orientation  1.1013561487197876\n",
      "Ang  5.34735009216243\n",
      "Diff -0.031094643041448045 orientation 5.378444735203878curr orientation  5.378444735203878\n",
      "Turn\n",
      "PID cv 0.9194909334182739 sp 0.5 error -0.4194909334182739 pid -0.4194909334182739Wall Follow\n",
      "PID cv 0.6744837164878845 sp 0.5 error -0.17448371648788452 pid -0.17448371648788452Wall Follow\n",
      "PID cv 0.5689622759819031 sp 0.5 error -0.06896227598190308 pid -0.06896227598190308Wall Follow\n",
      "PID cv 0.5022726058959961 sp 0.5 error -0.0022726058959960938 pid -0.0022726058959960938Wall Follow\n",
      "Avoid Obstacle\n",
      "Avoid Obstacle\n",
      "PID cv 0.3025190830230713 sp 0.5 error 0.1974809169769287 pid 0.1974809169769287Wall Follow\n",
      "Avoid Obstacle\n",
      "Avoid Obstacle\n",
      "Avoid Obstacle\n",
      "PID cv 0.13345475494861603 sp 0.5 error 0.36654524505138397 pid 0.36654524505138397Wall Follow\n",
      "Avoid Obstacle\n",
      "PID cv 0.13014402985572815 sp 0.5 error 0.36985597014427185 pid 0.36985597014427185Wall Follow\n",
      "PID cv 0.20641125738620758 sp 0.5 error 0.2935887426137924 pid 0.2935887426137924Wall Follow\n",
      "PID cv 0.2713518440723419 sp 0.5 error 0.22864815592765808 pid 0.22864815592765808Wall Follow\n",
      "PID cv 0.32495924830436707 sp 0.5 error 0.17504075169563293 pid 0.17504075169563293Wall Follow\n",
      "Avoid Obstacle\n",
      "Go direction  -1.1945726979583369 Robot direction  2.770505905151367\n",
      "Initial orientation  2.770505905151367\n",
      "Ang  5.088612609221249\n",
      "Diff 0.032055486360205165 orientation 5.056557122861044curr orientation  5.056557122861044\n",
      "Turn\n",
      "PID cv 0.3073660135269165 sp 0.5 error 0.1926339864730835 pid 0.1926339864730835Wall Follow\n",
      "PID cv 0.2778454124927521 sp 0.5 error 0.22215458750724792 pid 0.22215458750724792Wall Follow\n",
      "PID cv 0.27582550048828125 sp 0.5 error 0.22417449951171875 pid 0.22417449951171875Wall Follow\n",
      "PID cv 0.2914251387119293 sp 0.5 error 0.20857486128807068 pid 0.20857486128807068Wall Follow\n",
      "PID cv 0.32601049542427063 sp 0.5 error 0.17398950457572937 pid 0.17398950457572937Wall Follow\n",
      "PID cv 0.3908904492855072 sp 0.5 error 0.1091095507144928 pid 0.1091095507144928Wall Follow\n",
      "PID cv 0.4724176228046417 sp 0.5 error 0.027582377195358276 pid 0.027582377195358276Wall Follow\n",
      "PID cv 0.5425524115562439 sp 0.5 error -0.042552411556243896 pid -0.042552411556243896Wall Follow\n",
      "Avoid Obstacle\n",
      "Avoid Obstacle\n",
      "PID cv 0.2640576958656311 sp 0.5 error 0.2359423041343689 pid 0.2359423041343689Wall Follow\n",
      "PID cv 0.3559774160385132 sp 0.5 error 0.14402258396148682 pid 0.14402258396148682Wall Follow\n",
      "PID cv 0.4756450653076172 sp 0.5 error 0.024354934692382812 pid 0.024354934692382812Wall Follow\n",
      "PID cv 0.5736103653907776 sp 0.5 error -0.07361036539077759 pid -0.07361036539077759Wall Follow\n",
      "PID cv 0.6361734867095947 sp 0.5 error -0.13617348670959473 pid -0.13617348670959473Wall Follow\n",
      "PID cv 0.6735256910324097 sp 0.5 error -0.17352569103240967 pid -0.17352569103240967Wall Follow\n",
      "PID cv 0.6921184062957764 sp 0.5 error -0.19211840629577637 pid -0.19211840629577637Wall Follow\n",
      "PID cv 0.7124395966529846 sp 0.5 error -0.21243959665298462 pid -0.21243959665298462Wall Follow\n",
      "PID cv 0.7323068380355835 sp 0.5 error -0.2323068380355835 pid -0.2323068380355835Wall Follow\n",
      "PID cv 0.7123706340789795 sp 0.5 error -0.2123706340789795 pid -0.2123706340789795Wall Follow\n",
      "PID cv 0.6652481555938721 sp 0.5 error -0.16524815559387207 pid -0.16524815559387207Wall Follow\n",
      "PID cv 0.6296018958091736 sp 0.5 error -0.12960189580917358 pid -0.12960189580917358Wall Follow\n",
      "PID cv 0.5862484574317932 sp 0.5 error -0.08624845743179321 pid -0.08624845743179321Wall Follow\n",
      "PID cv 0.5298765301704407 sp 0.5 error -0.029876530170440674 pid -0.029876530170440674Wall Follow\n",
      "PID cv 0.4605865776538849 sp 0.5 error 0.03941342234611511 pid 0.03941342234611511Wall Follow\n",
      "Avoid Obstacle\n",
      "PID cv 0.4285524785518646 sp 0.5 error 0.07144752144813538 pid 0.07144752144813538Wall Follow\n",
      "PID cv 0.5990636348724365 sp 0.5 error -0.09906363487243652 pid -0.09906363487243652Wall Follow\n",
      "PID cv 0.6605226397514343 sp 0.5 error -0.16052263975143433 pid -0.16052263975143433Wall Follow\n",
      "PID cv 0.6905275583267212 sp 0.5 error -0.1905275583267212 pid -0.1905275583267212Wall Follow\n",
      "PID cv 0.7083165049552917 sp 0.5 error -0.20831650495529175 pid -0.20831650495529175Wall Follow\n",
      "PID cv 0.722652792930603 sp 0.5 error -0.22265279293060303 pid -0.22265279293060303Wall Follow\n",
      "PID cv 0.7494098544120789 sp 0.5 error -0.24940985441207886 pid -0.24940985441207886Wall Follow\n",
      "PID cv 0.7319435477256775 sp 0.5 error -0.2319435477256775 pid -0.2319435477256775Wall Follow\n",
      "PID cv 0.6850327849388123 sp 0.5 error -0.18503278493881226 pid -0.18503278493881226Wall Follow\n",
      "PID cv 0.6517740488052368 sp 0.5 error -0.15177404880523682 pid -0.15177404880523682Wall Follow\n",
      "PID cv 0.6122075319290161 sp 0.5 error -0.11220753192901611 pid -0.11220753192901611Wall Follow\n",
      "PID cv 0.5562763214111328 sp 0.5 error -0.05627632141113281 pid -0.05627632141113281Wall Follow\n",
      "PID cv 0.4843137562274933 sp 0.5 error 0.015686243772506714 pid 0.015686243772506714Wall Follow\n",
      "PID cv 0.39434731006622314 sp 0.5 error 0.10565268993377686 pid 0.10565268993377686Wall Follow\n",
      "PID cv 0.29524892568588257 sp 0.5 error 0.20475107431411743 pid 0.20475107431411743Wall Follow\n",
      "PID cv 0.2619224786758423 sp 0.5 error 0.23807752132415771 pid 0.23807752132415771Wall Follow\n"
     ]
    }
   ],
   "source": [
    "mr.start(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
