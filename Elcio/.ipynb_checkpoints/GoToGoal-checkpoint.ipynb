{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install anglr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from robot import Robot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import vrep\n",
    "import math\n",
    "\n",
    "from anglr import Angle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinematic_model:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "        \n",
    "        #Handles dos motores\n",
    "        ret1, self.motorLeft = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret2, self.motorRight = vrep.simxGetObjectHandle(self.robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        #Calcula distancia de eixo\n",
    "        res, left_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_leftMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, lpos = vrep.simxGetObjectPosition(robot.clientID, left_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        res, right_handle = vrep.simxGetObjectHandle(robot.clientID, \"Pioneer_p3dx_rightMotor\", vrep.simx_opmode_oneshot_wait)\n",
    "        ret, rpos = vrep.simxGetObjectPosition(robot.clientID, right_handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        # eixo\n",
    "        self.l = (abs(lpos[1]) + abs(rpos[1]))/2\n",
    "        \n",
    "        #Ao ser criado, coleta a referencia de zero do robo\n",
    "        pos = self.robot.get_current_position()\n",
    "        self.initial_pos_x = pos[0]\n",
    "        self.initial_pos_y = pos[1]\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        self.initial_orientation = orientation[2]\n",
    "\n",
    "        #Alem de mantermos a pose inicial, manteremos a pose atualizada do robo\n",
    "        self.enc_global_x = self.initial_pos_x\n",
    "        self.enc_global_y = self.initial_pos_y\n",
    "        self.enc_Theta = self.initial_orientation\n",
    "        \n",
    "        self.time_global_x = self.initial_pos_x\n",
    "        self.time_global_y = self.initial_pos_y\n",
    "        self.time_Theta = self.initial_orientation\n",
    "        \n",
    "        #Lista de pontos para o caminho do robo\n",
    "        self.enc_path = []\n",
    "        self.time_path = []\n",
    "        self.true_path = []\n",
    "        self.update_paths()\n",
    "        \n",
    "        #inicializando a posição dos encoders\n",
    "        self.jL = self.current_encoder_left()\n",
    "        self.jR = self.current_encoder_right()\n",
    "        \n",
    "        #intervalo entre cada calculo\n",
    "        self.compute_interval = 0.1\n",
    "        self.previous_timestamp = 0\n",
    "        \n",
    "    def update_paths(self):\n",
    "        self.enc_path.append([self.enc_global_x, self.enc_global_y, self.enc_Theta])\n",
    "        self.time_path.append([self.time_global_x, self.time_global_y, self.time_Theta])\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        true_theta = orientation[2]\n",
    "        current_position = self.true_global_position()\n",
    "        self.true_path.append([current_position[0], current_position[1], true_theta])\n",
    "    \n",
    "    def true_global_position(self):\n",
    "        pos = self.robot.get_current_position()\n",
    "        return pos[0],pos[1]\n",
    "    \n",
    "    def enc_global_position(self):\n",
    "        return self.enc_global_x, self.enc_global_y, self.enc_Theta\n",
    "    \n",
    "    def time_global_position(self):\n",
    "        return self.time_global_x, self.time_global_y, self.time_Theta\n",
    "    \n",
    "    \n",
    "    ##Esta seção esta relacionada ao calculo da posição levando em consideração os encoders\n",
    "    def current_encoder_left(self):\n",
    "        ret,jL = vrep.simxGetJointPosition(self.robot.clientID,self.motorLeft,vrep.simx_opmode_oneshot_wait)\n",
    "        return jL\n",
    "    def current_encoder_right(self):\n",
    "        ret, jR = vrep.simxGetJointPosition(self.robot.clientID,self.motorRight,vrep.simx_opmode_oneshot_wait)\n",
    "        return jR\n",
    "        \n",
    "    #Phi speed of rotation of wheels\n",
    "    def Xr(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Xr = (r*Phi_left/2) + (r*Phi_right/2)\n",
    "        return Xr\n",
    "    \n",
    "    def Theta_r(self, Phi_right, Phi_left):\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Tr = r*Phi_right/(2*self.l) - r*Phi_left/(2*self.l) \n",
    "        return Tr\n",
    "        \n",
    "    def speed_model(self,Phi_right,Phi_left):\n",
    "        #Se formos considerar que o eixo das rodas do robo está deslocado do eixo x\n",
    "        #return np.array([self.Xr(Phi_right,Phi_left),self.Theta_r(Phi_right,Phi_left)*self.l2,self.Theta_r(Phi_right,Phi_left)])\n",
    "        return np.array([self.Xr(Phi_right,Phi_left),0,self.Theta_r(Phi_right,Phi_left)])\n",
    "        \n",
    "    def inverse_rotation_matrix(self, ang):\n",
    "        Trot = np.array([[math.cos(ang), -math.sin(ang), 0], [math.sin(ang), math.cos(ang), 0], [0,0,1]])\n",
    "        return Trot\n",
    "    \n",
    "    def locomotion_global(self, ang, Phi_right, Phi_left):\n",
    "        return np.dot(self.inverse_rotation_matrix(ang),self.speed_model(Phi_right,Phi_left))\n",
    "    \n",
    "    def compute_with_encoder(self):\n",
    "        dxR = self.current_encoder_right() - self.jR\n",
    "        dxL = self.current_encoder_left() - self.jL\n",
    "        if (dxL>=0):\n",
    "            dxL=math.fmod(dxL+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxL=math.fmod(dxL-math.pi,2*math.pi)+math.pi\n",
    "        if (dxR>=0):\n",
    "            dxR=math.fmod(dxR+math.pi,2*math.pi)-math.pi\n",
    "        else:\n",
    "            dxR=math.fmod(dxR-math.pi,2*math.pi)+math.pi\n",
    "        qsi = self.locomotion_global(self.enc_Theta,dxR, dxL)\n",
    "        #Atualiza a posição global\n",
    "        self.enc_global_x = self.enc_global_x + qsi[0]\n",
    "        self.enc_global_y = self.enc_global_y + qsi[1]\n",
    "        self.enc_Theta = self.enc_Theta + qsi[2]\n",
    "        #Atualiza a posição dos encoders\n",
    "        self.jR = self.current_encoder_right()\n",
    "        self.jL = self.current_encoder_left()\n",
    "    ##Fim da seção relacionada ao calculo da posição levando em consideração os encoders        \n",
    "    \n",
    "    def compute_with_time(self, Phi_right, Phi_left):\n",
    "        #Calculo do delta S\n",
    "        r = self.robot.WHEEL_RADIUS\n",
    "        Vr = r*Phi_right\n",
    "        Vl = r*Phi_left\n",
    "        current_timestamp = datetime.timestamp(datetime.now())\n",
    "        Delta_t = current_timestamp - self.previous_timestamp\n",
    "        #atualiza timestamp imediatamente\n",
    "\n",
    "        self.previous_timestamp = current_timestamp\n",
    "        \n",
    "        Delta_s = (Vr + Vl)*Delta_t/2  \n",
    "        Delta_Theta = (Vr - Vl)*Delta_t/(2*self.l)\n",
    "    \n",
    "        self.time_global_x = self.time_global_x + Delta_s*math.cos(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_global_y = self.time_global_y + Delta_s*math.sin(self.time_Theta + Delta_Theta/2)\n",
    "        self.time_Theta = self.time_Theta + Delta_Theta\n",
    "    \n",
    "    def move(self,Phi_right, Phi_left,seconds): #velocidade em rad/s\n",
    "        #Vamos fixar um tempo de 500ms para computar as distâncias\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #self.compute()\n",
    "            self.robot.set_right_velocity(Phi_right)\n",
    "            self.robot.set_left_velocity(Phi_left)\n",
    "            time.sleep(self.compute_interval)\n",
    "            self.compute_with_encoder()\n",
    "            self.compute_with_time(Phi_right, Phi_left)\n",
    "            self.update_paths()\n",
    "        self.robot.stop()\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def turnGlobal(self, input_ang):\n",
    "        orientation = self.robot.get_current_orientation()[2]\n",
    "        ang = input_ang\n",
    "        if (orientation < 0):\n",
    "            orientation = orientation + 2*math.pi\n",
    "        if (ang < 0):\n",
    "            ang = ang + 2*math.pi\n",
    "            \n",
    "        print(\"Initial orientation \", orientation)\n",
    "        print(\"Ang \", ang)\n",
    "        vel = 0.2\n",
    "        \n",
    "        if ((ang - orientation) > math.pi) or (0 > (ang - orientation) > -math.pi):\n",
    "            vel = - vel\n",
    "        \n",
    "        self.robot.set_right_velocity(vel)\n",
    "        self.robot.set_left_velocity(-vel)\n",
    "        tolerance = math.pi/90\n",
    "        while ((ang - orientation) > tolerance) or ((ang - orientation) < -tolerance):\n",
    "            time.sleep(0.05)\n",
    "            orientation = self.robot.get_current_orientation()[2]\n",
    "            if (orientation < 0):\n",
    "                orientation = orientation + 2*math.pi\n",
    "            sys.stdout.write(\"\\r\" + \"Diff \" + str((ang - orientation)) + \" orientation \" + str(orientation))\n",
    "            sys.stdout.flush()\n",
    "        self.robot.stop()\n",
    "        print(\"curr orientation \", orientation)\n",
    "    \n",
    "    def ICR_left(self, Phi_left, R, seconds):\n",
    "        Phi_right = Phi_left*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_left Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "    \n",
    "    def ICR_right(self, Phi_right, R, seconds):\n",
    "        Phi_left = Phi_right*(R + self.l)/(R - self.l)\n",
    "        print(\"ICR_right Phi_r {} Phi_l {}\".format(Phi_right, Phi_left))\n",
    "        self.move(Phi_right, Phi_left, seconds)\n",
    "  \n",
    "    def plot_paths(self):\n",
    "        enc_path = np.array(self.enc_path)\n",
    "        time_path = np.array(self.time_path)\n",
    "        true_path = np.array(self.true_path)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "        ax[0].scatter(enc_path[:,0], enc_path[:,1], 5, c='b', marker='o')\n",
    "        #ax[1].scatter(time_path[:,0], time_path[:,1], 5, c='g', marker='o')\n",
    "        ax[1].scatter(true_path[:,0], true_path[:,1], 5, c='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser_sensor:\n",
    "    def __init__(self,robot):\n",
    "        self.robot = robot\n",
    "\n",
    "    def update_robot_frame_reading(self):\n",
    "        laser_flatten_readings = np.array(self.robot.read_laser())\n",
    "        laser_readings = laser_flatten_readings.reshape((len(laser_flatten_readings)//3, 3))\n",
    "        self.laser_x = laser_readings[:,0]\n",
    "        self.laser_y = laser_readings[:,1]\n",
    "\n",
    "class Us_sensor:\n",
    "    def __init__(self,robot):\n",
    "        orientation_angles = np.array([90,50,30,10,-10,-30,-50,-90,-90,-130,-150,-170,170,150,130,90])\n",
    "        orientation_rad = np.radians(orientation_angles)\n",
    "        self.data = {\n",
    "        \"prefix\" : \"Pioneer_p3dx_ultrasonicSensor\",\n",
    "        \"ids\" : np.arange(1,17,1), \"handles\" : np.zeros(16, dtype=int), \n",
    "        \"positions\" :  np.zeros((16,3),dtype=float),\n",
    "        \"angles_deg\": orientation_angles,\n",
    "        \"angles_rad\": orientation_rad,\n",
    "        \"raw_reading\": np.zeros(16),\n",
    "        \"robot_frame_reading\": np.zeros((16,2),dtype=float)\n",
    "        }\n",
    "        self.robot = robot\n",
    "        \n",
    "        for i,sensor_i in enumerate(self.data['ids']):\n",
    "            ret,handle = vrep.simxGetObjectHandle(self.robot.clientID, self.data['prefix'] + str(sensor_i), vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['handles'][i] = handle\n",
    "            ret, pos = vrep.simxGetObjectPosition(self.robot.clientID, handle, self.robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            #ret, ang = vrep.simxGetObjectOrientation(robot.clientID, handle, robot.robot_handle, vrep.simx_opmode_oneshot_wait)\n",
    "            self.data['positions'][i,:] = pos\n",
    "            #ultrassonic_sensors[sensor_i,4:7] = ang\n",
    "            \n",
    "    def get_left_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        #return np.min(np.array([self.data[\"raw_reading\"][0],self.data[\"raw_reading\"][1],self.data[\"raw_reading\"][15],self.data[\"raw_reading\"][14]]))\n",
    "        return np.array(self.data[\"raw_reading\"][0])\n",
    "    \n",
    "    def get_front_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][2:6]]))\n",
    "        #return np.min(np.array([self.data[\"raw_reading\"][2:4]]))\n",
    "    \n",
    "    def get_right_distance(self):\n",
    "        self.update_raw_reading()\n",
    "        return np.min(np.array([self.data[\"raw_reading\"][6:10]]))\n",
    "    \n",
    "    def update_raw_reading(self):\n",
    "        self.data[\"raw_reading\"] = np.array(self.robot.read_ultrassonic_sensors())\n",
    "    \n",
    "    def update_robot_frame_reading(self):\n",
    "        self.update_raw_reading()\n",
    "        for i, proximity in enumerate(us_sensors.data[\"raw_reading\"]):\n",
    "            if proximity == 5 or proximity < 0.1:\n",
    "                self.data[\"robot_frame_reading\"][i] = np.zeros(2)\n",
    "            else:\n",
    "                self.data[\"robot_frame_reading\"][i] = self.proximity_robot_frame(i+1,proximity).flatten()\n",
    "                \n",
    "        #toRobotFrame = lambda sensorId,proximity: self.proximity_robot_frame(sensorId,proximity)\n",
    "        #self.data[\"robot_frame_reading\"] = toRobotFrame(range(1,17,1),us_sensors.data[\"raw_reading\"])\n",
    "    \n",
    "    #Calcula o ponto no frame do robo, referente a leitura de cada sensor de proximidade\n",
    "    def proximity_robot_frame(self,sensorId, proximity):\n",
    "        index = sensorId -1\n",
    "        angulars = self.data[\"angles_rad\"][index]\n",
    "        #Matriz de rotação\n",
    "        rot_matrix = np.array([[math.cos(angulars),-math.sin(angulars)],[math.sin(angulars),math.cos(angulars)]])\n",
    "        #Rotacionando a leitura\n",
    "        distXY = np.dot(rot_matrix , np.array([[proximity],[0]]))\n",
    "        #Matriz de translação\n",
    "        posicao_sensor_x = self.data[\"positions\"][index][0]\n",
    "        posicao_sensor_y = self.data[\"positions\"][index][1]\n",
    "        transXY=np.array([[distXY[0][0]+posicao_sensor_x],[distXY[1][0]+posicao_sensor_y]])\n",
    "        return transXY\n",
    "\n",
    "class PointCloud():\n",
    "    def __init__(self, robot, us_sensors, laser_sensor):\n",
    "        self.robot = robot\n",
    "        self.us_sensors = us_sensors\n",
    "        self.laser_sensor = laser_sensor\n",
    "        \n",
    "        self.ultrassonic_points = []\n",
    "        self.laser_points = []\n",
    "        self.robot_points = []\n",
    "    \n",
    "    def update(self):\n",
    "        #Insere posição atual do robo\n",
    "        robot_x = self.robot.get_current_position()[0]\n",
    "        robot_y = self.robot.get_current_position()[1]\n",
    "        robot_ang = self.robot.get_current_orientation()[2]\n",
    "        \n",
    "        self.robot_points.append([robot_x,robot_y])\n",
    "\n",
    "        #Atualiza a leitura do laser e insere na nuvem de pontos\n",
    "        self.laser_sensor.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.laser_sensor.laser_x, self.laser_sensor.laser_y):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.laser_points.append([x,y])\n",
    "\n",
    "        #Atualiza a leitura do ultrassonico e insere na nuvem de pontos\n",
    "        self.us_sensors.update_robot_frame_reading()\n",
    "        for pointx, pointy in zip(self.us_sensors.data['robot_frame_reading'][:,0], self.us_sensors.data['robot_frame_reading'][:,1]):\n",
    "            x,y = toGlobal(robot_x, robot_y,robot_ang, pointx, pointy)\n",
    "            self.ultrassonic_points.append([x,y])\n",
    "    \n",
    "    def plot_point_cloud(self):\n",
    "        #Convertendo a nuvem de pontos em um array\n",
    "        ultrassonic_point_array = np.array(self.ultrassonic_points)\n",
    "        laser_point_array = np.array(self.laser_points)\n",
    "        robot_path = np.array(self.robot_points)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        #posição do centro do robo\n",
    "        ax[0].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[0].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[0].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor ultrassonico\n",
    "        ax[0].scatter(ultrassonic_point_array[:,0],ultrassonic_point_array[:,1], 10, c='magenta', marker='.')\n",
    "\n",
    "        #posição do centro do robo\n",
    "        ax[1].scatter(robot_path[:,0], robot_path[:,1], 40, c='b', marker='o')\n",
    "        #ax[1].plot(robot_path[:,0], robot_path[:,1],'.-')\n",
    "        pass_count = 0\n",
    "        for x, y in zip(robot_path[:,0], robot_path[:,1]):\n",
    "            ax[1].text(x, y, str(pass_count), color=\"black\", fontsize=12)\n",
    "            pass_count += 1\n",
    "        #posição dos pontos lidos pelo sensor laser\n",
    "        ax[1].scatter(laser_point_array[:,0],laser_point_array[:,1], 10, c='r', marker='.')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class PID():\n",
    "    def __init__(self, P=1, I=0.0, D=0.0, Derivator=0, Integrator=0, Integrator_max=500, Integrator_min=-500):\n",
    "        self.Kp=P\n",
    "        self.Ki=I\n",
    "        self.Kd=D\n",
    "        self.Derivator=Derivator\n",
    "        self.Integrator=Integrator\n",
    "        self.Integrator_max=Integrator_max\n",
    "        self.Integrator_min=Integrator_min\n",
    "        self.set_point=0.0\n",
    "        self.error=0.0\n",
    "\n",
    "    def update(self,current_value):\n",
    "        self.error = self.set_point - current_value\n",
    "        self.P_value = self.Kp * self.error\n",
    "        self.D_value = self.Kd * ( self.error - self.Derivator)\n",
    "        self.Derivator = self.error\n",
    "        self.Integrator = self.Integrator + self.error\n",
    "\n",
    "        if self.Integrator > self.Integrator_max:\n",
    "            self.Integrator = self.Integrator_max\n",
    "        elif self.Integrator < self.Integrator_min:\n",
    "            self.Integrator = self.Integrator_min\n",
    "\n",
    "        self.I_value = self.Integrator * self.Ki\n",
    "\n",
    "        PID = self.P_value + self.I_value + self.D_value\n",
    "        print(\"PID cv \",current_value ,\" sp \", self.set_point ,\" error \", self.error ,\" pid \", PID)\n",
    "        return PID\n",
    "\n",
    "    def setPoint(self,set_point):\n",
    "        self.set_point = set_point\n",
    "        self.Integrator=0\n",
    "        self.Derivator=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,robot_x],[0,1,robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),-math.sin(robot_ang),0],[math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_trans,T_rot)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    return res[0],res[1]\n",
    "\n",
    "def plot_lase_robot_frame():\n",
    "    fig, ax = plt.subplots()\n",
    "    #posição dos feixes laser\n",
    "    ax.scatter(laser_sensor.laser_x, laser_sensor.laser_y, 3, c='g', marker='o')\n",
    "    #posição do centro do robo\n",
    "    ax.scatter(0, 0, 40, c='b', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def fromGlobal(robot_x, robot_y,robot_ang, Point_xr, Point_yr):\n",
    "    T_trans = np.array([[1,0,-robot_x],[0,1,-robot_y],[0,0,1]])\n",
    "    T_rot = np.array([[math.cos(robot_ang),math.sin(robot_ang),0],[-math.sin(robot_ang),math.cos(robot_ang),0],[0,0,1]])\n",
    "    T = np.dot(T_rot,T_trans)\n",
    "    res = np.dot(T, np.array([Point_xr,Point_yr,1]))\n",
    "    ang = np.arctan2(res[1],res[0])\n",
    "    return res[0],res[1], ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### ---------------------------------------------------------  CÓDIGO PARA EDIÇÃO  ----------------------------------------------------------\n",
    "### -------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileRobot():\n",
    "    def __init__(self):\n",
    "        self.go_x = 0\n",
    "        self.go_y = 0\n",
    "        self.robot = Robot()\n",
    "        self.kinematicModel = Kinematic_model(self.robot)\n",
    "        self.us_sensors = Us_sensor(self.robot)\n",
    "        self.laser_sensors = Laser_sensor(self.robot)\n",
    "        self.pidL = PID()\n",
    "        self.pidL.setPoint(0.5)\n",
    "#         self.pidF = PID()\n",
    "#         self.pidF.setPoint(1)\n",
    "        self.compute_interval = 0.5\n",
    "        self.follow_wall_side = \"LEFT\"\n",
    "        \n",
    "        self.curr_state = None\n",
    "        self.prev_state = None\n",
    "        \n",
    "    def checkCurrentState(self):\n",
    "        previous_state = self.curr_state\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        \n",
    "        #Initial state: Move Foward\n",
    "        if (previous_state == None and self.prev_state == None):\n",
    "            self.curr_state = 'CalcDirection'\n",
    "        \n",
    "        #CD -> MF\n",
    "        if (previous_state == 'CalcDirection' and front >= 0.5):\n",
    "            self.curr_state = 'MoveFoward'\n",
    "        \n",
    "        #MF->TR\n",
    "        if (previous_state == 'MoveFoward' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #TR->WF\n",
    "        if (previous_state == 'TurnRight' and left <= 0.8):\n",
    "            self.curr_state = 'WallFollow'\n",
    "            \n",
    "        #WF->TR\n",
    "        if (previous_state == 'WallFollow' and front <= 0.5):\n",
    "            self.curr_state = 'TurnRight'\n",
    "            \n",
    "        #WF->MoveFoward\n",
    "        if (previous_state == 'WallFollow' and front == 5 and left > 0.7):\n",
    "            self.curr_state = 'CalcDirection'\n",
    "          \n",
    "        #update prev\n",
    "        self.prev_state = previous_state\n",
    "    \n",
    "    def control(self, left_distance, right_distance, front_distance ):\n",
    "        left = self.us_sensors.get_left_distance()\n",
    "        right = self.us_sensors.get_right_distance()\n",
    "        front = self.us_sensors.get_front_distance()\n",
    "        vel = 0\n",
    "        turn = 0\n",
    "        self.checkCurrentState()\n",
    "        \n",
    "        print(\"left \", left, \"right \", right, \"front \", front)\n",
    "        \n",
    "        #State Machine\n",
    "        ##Move foward\n",
    "        if (self.curr_state == 'MoveFoward'):\n",
    "            turn = 0\n",
    "            vel = 10\n",
    "        ##Turn Right\n",
    "        elif (self.curr_state == 'TurnRight'):\n",
    "            turn = 10\n",
    "            vel = 0\n",
    "        #Wall Follow\n",
    "        elif (self.curr_state == 'WallFollow'):\n",
    "            turn = self.pidL.update(left_distance)\n",
    "            vel = 10\n",
    "        #Turn Back\n",
    "#         elif (self.curr_state == 'TurnBack'):\n",
    "#             turn = -1\n",
    "#             vel = 0\n",
    "        #Calc Direction\n",
    "        elif (self.curr_state == 'CalcDirection'):\n",
    "            self.go_x\n",
    "            self.go_y\n",
    "            \n",
    "            turn = self.pidL.update(left_distance)\n",
    "            vel = 10\n",
    "        \n",
    "        \n",
    "        print(\"State: \", self.curr_state)\n",
    "        self.prev_state = self.curr_state\n",
    "        return vel + turn, vel - turn\n",
    "\n",
    "    def start(self, seconds):\n",
    "        for step in range(int(seconds/self.compute_interval)):\n",
    "            #Phi_l, Phi_r = self.braitenberg(self.us_sensors.data[\"raw_reading\"][:8],2)\n",
    "            Phi_l, Phi_r = self.control(self.us_sensors.get_left_distance(),self.us_sensors.get_right_distance(), self.us_sensors.get_front_distance())\n",
    "            self.kinematicModel.move(Phi_r, Phi_l,self.compute_interval)\n",
    "            #self.kinematicModel.plot_paths()\n",
    "            #self.point_cloud.update()\n",
    "            #self.point_cloud.plot_point_cloud()\n",
    "    \n",
    "    def teste(self):\n",
    "        give_diretion(self.robot, self.us_sensors, 0, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_diretion(robot, us_sensors, go_point_x, go_point_y):\n",
    "    \n",
    "    # global position of robot\n",
    "    robot_x = robot.get_current_position()[0]\n",
    "    robot_y = robot.get_current_position()[1]\n",
    "    robot_ang = robot.get_current_orientation()[2]\n",
    "    \n",
    "    # relative vector to goal\n",
    "    vec_x_go = go_point_x - robot_x\n",
    "    vec_y_go = go_point_y - robot_y\n",
    "    \n",
    "    # angle between position and goal vector\n",
    "    #vector origin\n",
    "    \n",
    "    ang = math.acos( vec_x_go / ( math.sqrt(math.pow(vec_x_go,2)+math.pow(vec_y_go,2)) ) )\n",
    "\n",
    "    print(\"ang:\")\n",
    "    print(ang)\n",
    "    print(\"ang robot:\")\n",
    "    print(robot_ang)\n",
    "    \n",
    "    mr.kinematicModel.turnGlobal(ang)\n",
    "    \n",
    "    print(\"After:\")\n",
    "    print(robot.get_current_orientation()[2])\n",
    "    \n",
    "    # plot\n",
    "    plt.plot([0,0],[-7.5,7.5], color='g')\n",
    "    plt.plot([-7.5,7.5], [0,0], color='r')\n",
    "    origin = [robot_x, robot_y]\n",
    "    \n",
    "    #plt.quiver(*origin, data1, data2, color=['b'], scale=30)\n",
    "    #plt.quiver(*origin, vec_x_sum, vec_y_sum, color=['r'])\n",
    "    plt.quiver(*origin, vec_x_go, vec_y_go, color=['g'])\n",
    "\n",
    "    plt.axis([-7.5,7.5,-7.5,7.5])\n",
    "    plt.show()\n",
    "    \n",
    "    # new direction [vector_x, vetor_y]\n",
    "    #return [alpha * vec_x_go + (1 - alpha) * vec_x_sum, alpha * vec_y_go + (1 - alpha) * vec_y_sum, robot_x, robot_y]\n",
    "        \n",
    "#give_diretion(robot, us_sensors, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    }
   ],
   "source": [
    "mr = MobileRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ang:\n",
      "2.3676012543645752\n",
      "ang robot:\n",
      "2.3762197494506836\n",
      "Initial orientation  2.3762197494506836\n",
      "Ang  2.3676012543645752\n",
      "curr orientation  2.3762197494506836\n",
      "After:\n",
      "2.3762176036834717\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mr.teste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
